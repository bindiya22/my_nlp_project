{"words": ["iop", "conference", "series", "material", "science", "engineering", "paper", "open", "access", "may", "also", "like", "text", "summarization", "technique", "application", "comparative", "review", "extractive", "text", "summarization", "indonesian", "language", "w", "widodo", "nugraheni", "p", "sari", "cite", "article", "virender", "dehru", "et", "al", "iop", "conf", "ser", "mater", "sci", "eng", "idea", "based", "sequential", "pattern", "mining", "deep", "learning", "text", "summarization", "maylawati", "j", "kumar", "f", "b", "kasmin", "et", "al", "view", "article", "online", "update", "enhancement", "chinese", "long", "text", "summarization", "using", "improved", "sequencetosequence", "lstm", "zanjie", "yao", "aixiang", "chen", "han", "xie", "content", "downloaded", "ip", "address", "ascus", "iop", "publishing", "iop", "conf", "series", "material", "science", "engineering", "doix", "text", "summarization", "technique", "application", "virender", "dehru", "pradeep", "kumar", "tiwari", "gaurav", "aggarwal", "bhavya", "joshi", "pawan", "kartik", "manipal", "university", "jaipur", "dehmi", "kalan", "jaipurajmer", "expressway", "jaipur", "rajasthan", "india", "email", "pradeeptiwarimcagmailcom", "abstract", "person", "need", "go", "page", "article", "given", "topic", "understand", "gist", "mere", "summary", "sufficient", "many", "case", "given", "rise", "many", "apps", "crunch", "hundred", "article", "generate", "personalized", "feed", "summary", "user", "go", "people", "access", "internet", "lot", "information", "created", "shared", "online", "give", "u", "luxury", "click", "away", "consumption", "however", "information", "filtered", "cleared", "noise", "work", "aim", "explore", "different", "technique", "text", "summarization", "evaluate", "different", "parameter", "extent", "compressionsummarization", "retention", "meaninggist", "grammatical", "error", "introduction", "information", "shared", "online", "text", "summarization", "becomes", "extremely", "relevant", "cited", "work", "field", "date", "back", "researcher", "proposed", "frequency", "word", "used", "statistical", "measure", "process", "still", "hold", "certain", "method", "one", "example", "news", "article", "person", "need", "go", "page", "article", "given", "topic", "understand", "gist", "mere", "summary", "sufficient", "many", "case", "given", "rise", "many", "apps", "crunch", "hundred", "article", "generate", "personalized", "feed", "summary", "user", "go", "another", "example", "social", "medium", "platform", "platform", "crunch", "thousand", "post", "given", "topic", "understand", "content", "overlap", "summarize", "content", "text", "summarization", "also", "used", "extent", "answer", "user", "query", "directly", "search", "result", "something", "search", "engine", "lately", "information", "shared", "consumed", "text", "summarization", "becomes", "relevant", "two", "main", "category", "text", "summarization", "extractive", "abstractive", "name", "suggest", "extractive", "emphasizes", "calculating", "weight", "sentence", "picking", "top", "k", "sentence", "summary", "abstractive", "emphasizes", "rewriting", "sentence", "generate", "summary", "extractive", "method", "suffers", "loss", "meaning", "extent", "connection", "sentence", "lost", "picking", "abstractive", "method", "requires", "lot", "effort", "training", "model", "trying", "avoid", "grammatical", "semantic", "mistake", "sentence", "often", "rewritten", "abstractive", "languagedependent", "extractive", "scaled", "certain", "language", "core", "idea", "remains", "consumption", "information", "becomes", "costly", "timeconsuming", "process", "information", "grows", "size", "presence", "irrelevant", "material", "noise", "text", "summarization", "used", "technique", "filter", "manual", "text", "summarization", "work", "best", "meaning", "text", "retained", "required", "grammatical", "error", "avoided", "however", "timeconsuming", "process", "contentfromthisworkmaybeusedunderthetermsofthecreativecommonsattributionlicenceanyfurtherdistribution", "ofthisworkmustmaintainattributiontotheauthorsandthetitleoftheworkjournalcitationanddoi", "publishedunderlicencebyioppublishingltd", "ascus", "iop", "publishing", "iop", "conf", "series", "material", "science", "engineering", "doix", "varying", "result", "another", "option", "use", "automatic", "text", "summarization", "computer", "equipped", "algorithm", "generate", "summary", "provided", "content", "however", "result", "might", "vary", "depending", "content", "algorithm", "used", "process", "automatic", "text", "summarization", "widely", "used", "different", "product", "service", "return", "affect", "user", "experience", "engaging", "product", "service", "application", "notable", "social", "medium", "platform", "use", "process", "generate", "summary", "post", "grouped", "based", "content", "called", "topic", "topic", "used", "engage", "user", "online", "google", "home", "feed", "example", "generates", "summary", "based", "user", "preference", "search", "engine", "today", "directly", "answer", "provided", "query", "rather", "providing", "link", "text", "extracted", "ranked", "credible", "website", "summary", "generated", "text", "returned", "answer", "query", "concept", "application", "voicebased", "assistant", "answering", "user", "query", "objective", "work", "explore", "different", "technique", "text", "summarization", "compare", "generated", "summary", "identify", "optimal", "parameter", "example", "k", "extractive", "text", "summarization", "best", "summary", "identify", "implement", "modification", "possible", "scale", "algorithm", "different", "language", "also", "identify", "different", "application", "automatic", "text", "summarization", "table", "show", "advantage", "disadvantage", "automatic", "text", "summarization", "advantage", "disadvantage", "table", "advantage", "disadvantage", "using", "automatic", "text", "summarization", "advantage", "disadvantage", "timesaving", "process", "might", "miss", "certain", "sentence", "affecting", "computer", "noticeably", "faster", "summary", "meaning", "human", "capable", "generating", "certain", "sentence", "contribute", "summary", "faster", "summary", "might", "omitted", "return", "might", "affect", "generated", "summary", "scalable", "effort", "put", "training", "model", "might", "automatic", "text", "summarization", "exactly", "meet", "required", "standard", "scaled", "different", "language", "neural", "networkbased", "model", "require", "large", "adoption", "proper", "algorithm", "whereas", "resource", "time", "train", "result", "might", "human", "limited", "extent", "exactly", "meet", "required", "standard", "expertise", "particular", "language", "level", "manual", "text", "summarization", "wide", "usage", "grammatical", "mistake", "abstractive", "algorithm", "automatic", "text", "summarization", "prone", "grammatical", "mistake", "abstractive", "used", "different", "field", "discussed", "method", "rewrite", "certain", "portion", "sentence", "overview", "thereby", "enhancing", "user", "generate", "summary", "chance", "experience", "engaging", "product", "sentence", "might", "contain", "grammatical", "service", "error", "affecting", "overall", "readability", "organization", "work", "first", "take", "overview", "theory", "concept", "technology", "check", "detailed", "methodology", "algorithm", "compare", "result", "performance", "method", "ascus", "iop", "publishing", "iop", "conf", "series", "material", "science", "engineering", "doix", "conceptual", "view", "concept", "theory", "theory", "extractive", "main", "concept", "used", "extractive", "text", "summarization", "focus", "important", "sentence", "sentence", "assigned", "weight", "heavier", "weight", "contributes", "summary", "different", "technique", "assigning", "weight", "sentence", "example", "word", "weighted", "frequency", "word", "frequency", "calculated", "freqwordmaxfreq", "occurrence", "important", "word", "sentence", "assigned", "weight", "number", "important", "word", "occur", "important", "word", "picked", "using", "certain", "filter", "ignore", "stop", "word", "common", "word", "collapse", "adjacent", "occurring", "word", "concept", "used", "textrank", "textrank", "work", "building", "graph", "sentence", "sentence", "considered", "node", "connection", "sentence", "called", "edge", "edge", "assigned", "weight", "score", "tell", "u", "extent", "sentence", "connected", "sentence", "connected", "linked", "number", "sentence", "deemed", "important", "picked", "generating", "summary", "top", "k", "sentence", "picked", "based", "score", "weight", "following", "greedy", "approach", "abstractive", "method", "based", "training", "deep", "learning", "model", "data", "help", "model", "learn", "understand", "language", "abstractive", "text", "summarization", "complex", "method", "automatically", "help", "computer", "learn", "grammar", "semantics", "language", "form", "new", "sentence", "summarize", "given", "text", "model", "typically", "based", "recurrent", "neural", "network", "figure", "depicts", "rnn", "architecture", "rnns", "special", "type", "neural", "network", "output", "previous", "step", "fed", "input", "current", "step", "normal", "neural", "network", "input", "output", "independent", "use", "rnns", "predict", "next", "word", "sequence", "previous", "word", "context", "gained", "required", "important", "feature", "rnn", "hidden", "state", "remembers", "information", "sequence", "rnn", "said", "memory", "remember", "previously", "learned", "information", "refer", "figure", "figure", "rnn", "basic", "architecture", "ascus", "iop", "publishing", "iop", "conf", "series", "material", "science", "engineering", "doix", "rnn", "current", "state", "function", "current", "input", "previous", "state", "successive", "input", "called", "time", "step", "next", "time", "step", "new", "ht", "becomes", "ht", "much", "time", "phase", "issue", "take", "go", "merge", "data", "previous", "state", "upon", "completion", "time", "step", "final", "current", "state", "used", "determine", "yt", "output", "output", "correlated", "real", "output", "producing", "error", "change", "weight", "error", "backpropagated", "network", "shall", "go", "backpropagation", "information", "section", "network", "trained", "special", "form", "called", "long", "short", "term", "memory", "network", "rnn", "used", "overcomes", "issue", "longterm", "rnn", "dependence", "concept", "term", "frequency", "inverse", "frequency", "text", "tfidf", "also", "used", "weighting", "factor", "data", "extraction", "text", "mining", "user", "modelling", "search", "meaning", "tfidf", "increase", "proportionally", "amount", "time", "word", "appears", "text", "offset", "number", "document", "containing", "word", "corpus", "tends", "respond", "fact", "certain", "word", "appear", "general", "often", "one", "common", "termweighting", "scheme", "today", "tfidf", "figure", "illustrates", "process", "document", "summarization", "refer", "figure", "tft", "number", "time", "term", "appears", "document", "total", "number", "term", "document", "b", "idft", "logetotal", "number", "document", "number", "document", "term", "required", "tfidf", "value", "b", "figure", "text", "summarization", "process", "vector", "exact", "standard", "way", "computer", "compare", "string", "sentence", "convert", "vector", "use", "vectorbased", "operator", "compute", "various", "value", "one", "ascus", "iop", "publishing", "iop", "conf", "series", "material", "science", "engineering", "doix", "example", "cosine", "similarity", "cosine", "similarity", "cosine", "similarity", "measure", "similarity", "two", "nonzero", "vector", "inner", "product", "space", "measure", "cosine", "angle", "similarity", "ab", "ab", "b", "vector", "stop", "word", "word", "contribute", "meaning", "nlp", "operation", "called", "stopwords", "removed", "part", "preprocessing", "sequencesequence", "modeling", "used", "special", "class", "sequence", "modeling", "problem", "use", "rnns", "input", "well", "output", "sequence", "model", "involve", "architecture", "called", "encoder", "decoder", "sequence", "modeling", "used", "speech", "recognition", "natural", "language", "processing", "computer", "understand", "natural", "language", "predict", "word", "sequence", "encoder", "neural", "network", "purpose", "interpreting", "constructing", "smaller", "dimensional", "representation", "input", "set", "point", "encoder", "process", "information", "collect", "contextual", "information", "present", "input", "sequence", "order", "initialise", "decoder", "hidden", "state", "hi", "cell", "state", "ci", "last", "time", "stage", "used", "figure", "display", "lstm", "process", "encoder", "figure", "encoder", "lstm", "decoder", "representation", "encoder", "redirected", "sequence", "created", "represent", "output", "read", "whole", "wordbyword", "predicts", "one", "timestep", "offset", "sequence", "sequence", "given", "prior", "word", "predicts", "next", "word", "special", "token", "applied", "target", "sequence", "prior", "feeding", "decoder", "start", "end", "decoder", "function", "illustrated", "figure", "ascus", "iop", "publishing", "iop", "conf", "series", "material", "science", "engineering", "doix", "figure", "decoder", "lstm", "inference", "process", "phase", "come", "training", "model", "used", "decode", "new", "source", "sequence", "target", "unknown", "attention", "mechanism", "used", "focus", "specific", "portion", "text", "predict", "next", "sequence", "implement", "attention", "mechanism", "input", "taken", "time", "step", "encoder", "weightage", "timesteps", "weightage", "depends", "importance", "time", "step", "decoder", "optimally", "generate", "next", "word", "sequence", "technology", "used", "nltk", "corpus", "stop", "word", "sklearns", "pairwise", "metric", "cosine", "similarity", "tfidf", "vectorizer", "google", "colab", "gpu", "training", "kera", "tensorflow", "bahdanau", "attention", "overcome", "problem", "long", "sentence", "performance", "basic", "encoderdecoder", "deteriorates", "rapidly", "length", "input", "sentence", "increase", "kaggle", "data", "collection", "methodology", "extractive", "method", "figure", "flow", "chart", "extractive", "text", "summarization", "ascus", "iop", "publishing", "iop", "conf", "series", "material", "science", "engineering", "doix", "exist", "many", "approach", "technique", "part", "extractive", "method", "mainly", "focus", "word", "weighted", "frequency", "text", "rank", "figure", "depict", "flow", "chart", "extractive", "text", "summarization", "word", "weighted", "frequency", "specified", "paragraph", "text", "first", "tokenized", "sentence", "sentence", "remove", "stop", "word", "punctuation", "entire", "model", "based", "frequency", "need", "keep", "track", "word", "frequency", "max", "frequency", "done", "preprocessing", "frequency", "calculation", "sentence", "compute", "weight", "done", "adding", "individual", "score", "word", "sentence", "score", "word", "defined", "freqwordmaxfreq", "score", "calculated", "greedy", "approach", "used", "pick", "top", "k", "sentence", "max", "k", "weight", "generate", "summary", "sentence", "reordered", "resorted", "order", "original", "appearance", "actual", "text", "also", "implemented", "hindi", "text", "using", "hindi", "stopwords", "got", "good", "result", "word", "probability", "another", "method", "used", "word", "probability", "instead", "dividing", "maxfreq", "divide", "n", "number", "word", "textrank", "textrank", "method", "based", "pagerank", "algorithm", "usually", "used", "rank", "web", "page", "search", "result", "build", "matrix", "size", "n", "x", "n", "cell", "filled", "probability", "user", "might", "visit", "site", "number", "unique", "link", "web", "page", "wi", "value", "updated", "interactively", "textrank", "work", "similarly", "build", "adjacent", "matrix", "size", "n", "x", "n", "n", "number", "sentence", "text", "sentence", "ni", "index", "compared", "nj", "j", "comparison", "based", "cosine", "similarity", "technique", "sentence", "compared", "entire", "matrix", "filled", "manner", "sentence", "ni", "entire", "row", "added", "compute", "score", "ni", "top", "k", "sentence", "picked", "based", "score", "greedy", "search", "sentence", "required", "summary", "adjacency", "matrix", "used", "time", "complexity", "increase", "adjacency", "list", "reduces", "complexity", "ov", "e", "processing", "graph", "textrank", "better", "realizing", "connection", "sentence", "vector", "used", "easy", "apply", "cosine", "similarity", "connection", "graph", "two", "sentence", "also", "tell", "u", "required", "meaningful", "context", "thus", "textrank", "work", "well", "figure", "showing", "adjacency", "matrix", "figure", "adjacency", "matrix", "typical", "example", "adjacency", "matrix", "cell", "filled", "value", "depicting", "connection", "node", "refer", "figure", "ascus", "iop", "publishing", "iop", "conf", "series", "material", "science", "engineering", "doix", "abstractive", "method", "abstractive", "method", "use", "deep", "learning", "model", "predict", "word", "sequence", "weve", "used", "long", "short", "term", "memory", "network", "special", "type", "recurrent", "neural", "network", "implemented", "using", "encoder", "decoder", "architecture", "set", "phase", "training", "inference", "handle", "long", "sentence", "weve", "used", "bahdanau", "attention", "layer", "help", "focus", "particular", "important", "part", "sentence", "methodology", "used", "implement", "deep", "learning", "model", "two", "datasets", "used", "news", "summary", "dataset", "kaggle", "contains", "column", "text", "headline", "food", "review", "amazon", "kaggle", "contains", "multiple", "column", "important", "text", "summary", "working", "mechanism", "procedure", "model", "implemented", "google", "colab", "using", "kera", "attention", "layer", "file", "downloaded", "internet", "implement", "bahdanau", "attention", "written", "published", "paper", "first", "review", "dataset", "read", "top", "row", "duplicate", "na", "value", "dropped", "data", "cleaned", "using", "typical", "text", "cleaning", "operation", "contraction", "mapping", "done", "expand", "english", "language", "contraction", "shouldnt", "text", "cleaned", "removing", "html", "tag", "contraction", "expanded", "removed", "parenthesis", "text", "removed", "stopwords", "removed", "short", "word", "removed", "done", "clean", "summary", "present", "datasets", "text", "preprocessing", "applied", "news", "dataset", "start", "end", "token", "added", "cleaned", "summary", "text", "length", "analyzed", "get", "maximum", "length", "text", "summary", "final", "data", "frame", "created", "contain", "data", "text", "summary", "equal", "set", "maximum", "data", "split", "train", "test", "set", "train", "test", "text", "summary", "word", "sequence", "converted", "integer", "sequence", "using", "tokenizers", "topmost", "common", "word", "encoder", "model", "consisting", "three", "lstm", "layer", "stacked", "top", "made", "decoder", "initialized", "encoder", "state", "dense", "layer", "softmax", "activation", "added", "end", "setting", "training", "phase", "encoder", "decoder", "model", "compiled", "using", "sparse", "categorical", "crossentropy", "loss", "function", "early", "stopping", "used", "stop", "training", "model", "validation", "loss", "started", "increasing", "review", "model", "stopped", "training", "epoch", "news", "epoch", "used", "due", "time", "machine", "power", "constraint", "encoder", "decoder", "inference", "phase", "set", "encoder", "input", "output", "training", "supplied", "input", "inference", "decoder", "set", "inference", "phase", "predict", "next", "word", "sequence", "initial", "state", "set", "state", "previous", "time", "step", "inference", "function", "decode", "input", "sequence", "created", "creates", "target", "sequence", "end", "token", "reached", "max", "summary", "length", "reached", "summary", "generated", "test", "set", "implementation", "result", "module", "implementation", "extractive", "weighted", "frequency", "module", "method", "pythontextsummarizerpyexhaustive", "getweightedfreq", "calculates", "score", "specified", "word", "based", "either", "word", "probability", "word", "frequency", "method", "populatefreq", "ascus", "iop", "publishing", "iop", "conf", "series", "material", "science", "engineering", "doix", "compute", "frequency", "table", "tokenizepara", "tokenizes", "paragraph", "based", "delimiter", "ktopranks", "return", "k", "top", "word", "summary", "formation", "textrank", "pythontextsummarizerpytextrank", "converttovec", "convert", "sentence", "vector", "representation", "sentencesimilarities", "build", "graph", "sentence", "node", "compute", "node", "edge", "sentence", "similarity", "ktopranks", "return", "k", "top", "word", "summary", "formation", "abstractive", "source", "python", "notebook", "model", "review", "dataset", "found", "open", "google", "drive", "google", "colab", "download", "source", "python", "notebook", "model", "news", "dataset", "found", "main", "module", "method", "cleantext", "used", "clean", "data", "text", "well", "summary", "decodesequence", "used", "predict", "test", "sequence", "using", "created", "model", "model", "based", "encoderdecoder", "lstm", "layer", "trained", "dataset", "set", "inference", "test", "set", "datasets", "module", "model", "used", "giving", "varying", "result", "result", "mainly", "evaluated", "news", "article", "general", "text", "model", "also", "implemented", "weighted", "frequency", "hindi", "text", "general", "text", "comprehension", "textrank", "slightly", "faster", "performed", "slightly", "better", "amongst", "extractive", "model", "sentence", "summary", "generated", "model", "seemed", "disconnected", "result", "sample", "test", "case", "viewed", "work", "used", "test", "paragraph", "test", "summarization", "text", "paragraph", "english", "second", "text", "paragraph", "hindi", "original", "text", "test", "paragraph", "democracy", "form", "government", "people", "get", "choose", "leader", "many", "democratic", "nation", "world", "process", "electing", "leader", "choice", "formation", "government", "varies", "country", "elect", "president", "others", "elect", "prime", "minister", "get", "vote", "people", "vote", "major", "factor", "democracy", "separation", "power", "check", "balance", "exist", "make", "sure", "every", "institution", "controlled", "democratic", "government", "function", "freely", "fairly", "widely", "considered", "key", "aspect", "ascus", "iop", "publishing", "iop", "conf", "series", "material", "science", "engineering", "doix", "democratic", "government", "choosing", "replacing", "government", "free", "fair", "election", "participation", "people", "process", "voting", "provision", "protection", "fundamental", "right", "rule", "law", "instance", "history", "people", "fought", "right", "right", "vote", "freely", "elect", "leader", "today", "healthy", "democracy", "let", "people", "vote", "also", "let", "hold", "leader", "accountable", "result", "depict", "threesentence", "summery", "sentence", "summary", "widely", "considered", "key", "aspect", "democratic", "government", "choosing", "replacing", "government", "free", "fair", "election", "participation", "people", "process", "voting", "provision", "protection", "fundamental", "right", "rule", "law", "sentence", "summary", "widely", "considered", "key", "aspect", "democratic", "government", "choosing", "replacing", "government", "free", "fair", "election", "participation", "people", "process", "voting", "provision", "protection", "fundamental", "right", "rule", "law", "today", "healthy", "democracy", "let", "people", "vote", "also", "let", "hold", "leader", "accountable", "sentence", "summary", "widely", "considered", "key", "aspect", "democratic", "government", "choosing", "replacing", "government", "free", "fair", "election", "participation", "people", "process", "voting", "provision", "protection", "fundamental", "right", "rule", "law", "instance", "history", "people", "fought", "right", "right", "vote", "freely", "elect", "leader", "today", "healthy", "democracy", "let", "people", "vote", "also", "let", "hold", "leader", "accountable", "test", "paragraph", "result", "depict", "threesentence", "summery", "sentence", "summary", "sentence", "summary", "ascus", "iop", "publishing", "iop", "conf", "series", "material", "science", "engineering", "doix", "sentence", "summary", "conclusion", "research", "show", "statisticalbased", "algorithm", "used", "generate", "fast", "decent", "summary", "breakthrough", "research", "paper", "published", "field", "neural", "network", "field", "nlp", "hardware", "improvement", "cpu", "gpu", "text", "summarization", "shall", "get", "reliable", "information", "shared", "online", "increase", "every", "year", "people", "spending", "time", "internet", "text", "summarization", "widely", "used", "enhance", "user", "experience", "data", "delivery", "everincreasing", "research", "better", "method", "field", "natural", "language", "processing", "future", "complex", "work", "done", "using", "model", "layer", "using", "completely", "new", "architecture", "like", "pointer", "generator", "network", "etc", "help", "computer", "understand", "natural", "language", "like", "never", "use", "various", "field", "reference", "gupta", "v", "lehal", "g", "survey", "text", "mining", "technique", "application", "journal", "emerging", "technology", "web", "intelligence", "ta", "kiyani", "f", "survey", "automatic", "text", "summarization", "press", "academia", "procedia", "allahyari", "pouriyeh", "assefi", "safaei", "trippe", "e", "gutierrez", "j", "b", "kochut", "k", "text", "summarization", "technique", "brief", "survey", "arxiv", "preprint", "arxiv", "nenkova", "mckeown", "k", "survey", "text", "summarization", "technique", "mining", "text", "data", "pp", "springer", "boston", "kanapala", "pal", "pamula", "r", "text", "summarization", "legal", "document", "survey", "artificial", "intelligence", "review", "wang", "l", "yao", "j", "tao", "zhong", "l", "liu", "w", "du", "q", "reinforced", "topicaware", "convolutional", "sequencetosequence", "model", "abstractive", "text", "summarization", "arxiv", "preprint", "arxiv", "kryscinski", "w", "mccann", "b", "xiong", "c", "socher", "r", "november", "evaluating", "factual", "consistency", "abstractive", "text", "summarization", "proceeding", "conference", "empirical", "method", "natural", "language", "processing", "emnlp", "pp", "song", "huang", "h", "ruan", "abstractive", "text", "summarization", "using", "lstmcnn", "based", "deep", "learning", "multimedia", "tool", "application", "ascus", "iop", "publishing", "iop", "conf", "series", "material", "science", "engineering", "doix", "cai", "h", "zheng", "v", "w", "chang", "k", "c", "c", "comprehensive", "survey", "graph", "embedding", "problem", "technique", "application", "ieee", "transaction", "knowledge", "data", "engineering", "kobayashi", "v", "b", "mol", "berkers", "h", "kismihk", "g", "den", "hartog", "n", "text", "mining", "organizational", "research", "organizational", "research", "method", "salloum", "alemran", "monem", "shaalan", "k", "using", "text", "mining", "technique", "extracting", "information", "research", "article", "intelligent", "natural", "language", "processing", "trend", "application", "pp", "springer", "cham", "qiang", "j", "qian", "z", "li", "yuan", "wu", "x", "short", "text", "topic", "modeling", "technique", "application", "performance", "survey", "ieee", "transaction", "knowledge", "data", "engineering"], "sentences": ["iop conference series material science engineering paper open access may also like text summarization technique application comparative review extractive text summarization indonesian language w widodo nugraheni p sari cite article virender dehru et al iop conf ser mater sci eng idea based sequential pattern mining deep learning text summarization maylawati j kumar f b kasmin et al view article online update enhancement chinese long text summarization using improved sequencetosequence lstm zanjie yao aixiang chen han xie content downloaded ip address ascus iop publishing iop conf series material science engineering doix text summarization technique application virender dehru pradeep kumar tiwari gaurav aggarwal bhavya joshi pawan kartik manipal university jaipur dehmi kalan jaipurajmer expressway jaipur rajasthan india email pradeeptiwarimcagmailcom abstract person need go page article given topic understand gist mere summary sufficient many case given rise many apps crunch hundred article generate personalized feed summary user go people access internet lot information created shared online give u luxury click away consumption however information filtered cleared noise work aim explore different technique text summarization evaluate different parameter extent compressionsummarization retention meaninggist grammatical error introduction information shared online text summarization becomes extremely relevant cited work field date back researcher proposed frequency word used statistical measure process still hold certain method one example news article person need go page article given topic understand gist mere summary sufficient many case given rise many apps crunch hundred article generate personalized feed summary user go another example social medium platform platform crunch thousand post given topic understand content overlap summarize content text summarization also used extent answer user query directly search result something search engine lately information shared consumed text summarization becomes relevant two main category text summarization extractive abstractive name suggest extractive emphasizes calculating weight sentence picking top k sentence summary abstractive emphasizes rewriting sentence generate summary extractive method suffers loss meaning extent connection sentence lost picking abstractive method requires lot effort training model trying avoid grammatical semantic mistake sentence often rewritten abstractive languagedependent extractive scaled certain language core idea remains consumption information becomes costly timeconsuming process information grows size presence irrelevant material noise text summarization used technique filter manual text summarization work best meaning text retained required grammatical error avoided however timeconsuming process contentfromthisworkmaybeusedunderthetermsofthecreativecommonsattributionlicenceanyfurtherdistribution ofthisworkmustmaintainattributiontotheauthorsandthetitleoftheworkjournalcitationanddoi publishedunderlicencebyioppublishingltd ascus iop publishing iop conf series material science engineering doix varying result another option use automatic text summarization computer equipped algorithm generate summary provided content however result might vary depending content algorithm used process automatic text summarization widely used different product service return affect user experience engaging product service application notable social medium platform use process generate summary post grouped based content called topic topic used engage user online google home feed example generates summary based user preference search engine today directly answer provided query rather providing link text extracted ranked credible website summary generated text returned answer query concept application voicebased assistant answering user query objective work explore different technique text summarization compare generated summary identify optimal parameter example k extractive text summarization best summary identify implement modification possible scale algorithm different language also identify different application automatic text summarization table show advantage disadvantage automatic text summarization advantage disadvantage table advantage disadvantage using automatic text summarization advantage disadvantage timesaving process might miss certain sentence affecting computer noticeably faster summary meaning human capable generating certain sentence contribute summary faster summary might omitted return might affect generated summary scalable effort put training model might automatic text summarization exactly meet required standard scaled different language neural networkbased model require large adoption proper algorithm whereas resource time train result might human limited extent exactly meet required standard expertise particular language level manual text summarization wide usage grammatical mistake abstractive algorithm automatic text summarization prone grammatical mistake abstractive used different field discussed method rewrite certain portion sentence overview thereby enhancing user generate summary chance experience engaging product sentence might contain grammatical service error affecting overall readability organization work first take overview theory concept technology check detailed methodology algorithm compare result performance method ascus iop publishing iop conf series material science engineering doix conceptual view concept theory theory extractive main concept used extractive text summarization focus important sentence sentence assigned weight heavier weight contributes summary different technique assigning weight sentence example word weighted frequency word frequency calculated freqwordmaxfreq occurrence important word sentence assigned weight number important word occur important word picked using certain filter ignore stop word common word collapse adjacent occurring word concept used textrank textrank work building graph sentence sentence considered node connection sentence called edge edge assigned weight score tell u extent sentence connected sentence connected linked number sentence deemed important picked generating summary top k sentence picked based score weight following greedy approach abstractive method based training deep learning model data help model learn understand language abstractive text summarization complex method automatically help computer learn grammar semantics language form new sentence summarize given text model typically based recurrent neural network figure depicts rnn architecture rnns special type neural network output previous step fed input current step normal neural network input output independent use rnns predict next word sequence previous word context gained required important feature rnn hidden state remembers information sequence rnn said memory remember previously learned information refer figure figure rnn basic architecture ascus iop publishing iop conf series material science engineering doix rnn current state function current input previous state successive input called time step next time step new ht becomes ht much time phase issue take go merge data previous state upon completion time step final current state used determine yt output output correlated real output producing error change weight error backpropagated network shall go backpropagation information section network trained special form called long short term memory network rnn used overcomes issue longterm rnn dependence concept term frequency inverse frequency text tfidf also used weighting factor data extraction text mining user modelling search meaning tfidf increase proportionally amount time word appears text offset number document containing word corpus tends respond fact certain word appear general often one common termweighting scheme today tfidf figure illustrates process document summarization refer figure tft number time term appears document total number term document b idft logetotal number document number document term required tfidf value b figure text summarization process vector exact standard way computer compare string sentence convert vector use vectorbased operator compute various value one ascus iop publishing iop conf series material science engineering doix example cosine similarity cosine similarity cosine similarity measure similarity two nonzero vector inner product space measure cosine angle similarity ab ab b vector stop word word contribute meaning nlp operation called stopwords removed part preprocessing sequencesequence modeling used special class sequence modeling problem use rnns input well output sequence model involve architecture called encoder decoder sequence modeling used speech recognition natural language processing computer understand natural language predict word sequence encoder neural network purpose interpreting constructing smaller dimensional representation input set point encoder process information collect contextual information present input sequence order initialise decoder hidden state hi cell state ci last time stage used figure display lstm process encoder figure encoder lstm decoder representation encoder redirected sequence created represent output read whole wordbyword predicts one timestep offset sequence sequence given prior word predicts next word special token applied target sequence prior feeding decoder start end decoder function illustrated figure ascus iop publishing iop conf series material science engineering doix figure decoder lstm inference process phase come training model used decode new source sequence target unknown attention mechanism used focus specific portion text predict next sequence implement attention mechanism input taken time step encoder weightage timesteps weightage depends importance time step decoder optimally generate next word sequence technology used nltk corpus stop word sklearns pairwise metric cosine similarity tfidf vectorizer google colab gpu training kera tensorflow bahdanau attention overcome problem long sentence performance basic encoderdecoder deteriorates rapidly length input sentence increase kaggle data collection methodology extractive method figure flow chart extractive text summarization ascus iop publishing iop conf series material science engineering doix exist many approach technique part extractive method mainly focus word weighted frequency text rank figure depict flow chart extractive text summarization word weighted frequency specified paragraph text first tokenized sentence sentence remove stop word punctuation entire model based frequency need keep track word frequency max frequency done preprocessing frequency calculation sentence compute weight done adding individual score word sentence score word defined freqwordmaxfreq score calculated greedy approach used pick top k sentence max k weight generate summary sentence reordered resorted order original appearance actual text also implemented hindi text using hindi stopwords got good result word probability another method used word probability instead dividing maxfreq divide n number word textrank textrank method based pagerank algorithm usually used rank web page search result build matrix size n x n cell filled probability user might visit site number unique link web page wi value updated interactively textrank work similarly build adjacent matrix size n x n n number sentence text sentence ni index compared nj j comparison based cosine similarity technique sentence compared entire matrix filled manner sentence ni entire row added compute score ni top k sentence picked based score greedy search sentence required summary adjacency matrix used time complexity increase adjacency list reduces complexity ov e processing graph textrank better realizing connection sentence vector used easy apply cosine similarity connection graph two sentence also tell u required meaningful context thus textrank work well figure showing adjacency matrix figure adjacency matrix typical example adjacency matrix cell filled value depicting connection node refer figure ascus iop publishing iop conf series material science engineering doix abstractive method abstractive method use deep learning model predict word sequence weve used long short term memory network special type recurrent neural network implemented using encoder decoder architecture set phase training inference handle long sentence weve used bahdanau attention layer help focus particular important part sentence methodology used implement deep learning model two datasets used news summary dataset kaggle contains column text headline food review amazon kaggle contains multiple column important text summary working mechanism procedure model implemented google colab using kera attention layer file downloaded internet implement bahdanau attention written published paper first review dataset read top row duplicate na value dropped data cleaned using typical text cleaning operation contraction mapping done expand english language contraction shouldnt text cleaned removing html tag contraction expanded removed parenthesis text removed stopwords removed short word removed done clean summary present datasets text preprocessing applied news dataset start end token added cleaned summary text length analyzed get maximum length text summary final data frame created contain data text summary equal set maximum data split train test set train test text summary word sequence converted integer sequence using tokenizers topmost common word encoder model consisting three lstm layer stacked top made decoder initialized encoder state dense layer softmax activation added end setting training phase encoder decoder model compiled using sparse categorical crossentropy loss function early stopping used stop training model validation loss started increasing review model stopped training epoch news epoch used due time machine power constraint encoder decoder inference phase set encoder input output training supplied input inference decoder set inference phase predict next word sequence initial state set state previous time step inference function decode input sequence created creates target sequence end token reached max summary length reached summary generated test set implementation result module implementation extractive weighted frequency module method pythontextsummarizerpyexhaustive getweightedfreq calculates score specified word based either word probability word frequency method populatefreq ascus iop publishing iop conf series material science engineering doix compute frequency table tokenizepara tokenizes paragraph based delimiter ktopranks return k top word summary formation textrank pythontextsummarizerpytextrank converttovec convert sentence vector representation sentencesimilarities build graph sentence node compute node edge sentence similarity ktopranks return k top word summary formation abstractive source python notebook model review dataset found open google drive google colab download source python notebook model news dataset found main module method cleantext used clean data text well summary decodesequence used predict test sequence using created model model based encoderdecoder lstm layer trained dataset set inference test set datasets module model used giving varying result result mainly evaluated news article general text model also implemented weighted frequency hindi text general text comprehension textrank slightly faster performed slightly better amongst extractive model sentence summary generated model seemed disconnected result sample test case viewed work used test paragraph test summarization text paragraph english second text paragraph hindi original text test paragraph democracy form government people get choose leader many democratic nation world process electing leader choice formation government varies country elect president others elect prime minister get vote people vote major factor democracy separation power check balance exist make sure every institution controlled democratic government function freely fairly widely considered key aspect ascus iop publishing iop conf series material science engineering doix democratic government choosing replacing government free fair election participation people process voting provision protection fundamental right rule law instance history people fought right right vote freely elect leader today healthy democracy let people vote also let hold leader accountable result depict threesentence summery sentence summary widely considered key aspect democratic government choosing replacing government free fair election participation people process voting provision protection fundamental right rule law sentence summary widely considered key aspect democratic government choosing replacing government free fair election participation people process voting provision protection fundamental right rule law today healthy democracy let people vote also let hold leader accountable sentence summary widely considered key aspect democratic government choosing replacing government free fair election participation people process voting provision protection fundamental right rule law instance history people fought right right vote freely elect leader today healthy democracy let people vote also let hold leader accountable test paragraph result depict threesentence summery sentence summary sentence summary ascus iop publishing iop conf series material science engineering doix sentence summary conclusion research show statisticalbased algorithm used generate fast decent summary breakthrough research paper published field neural network field nlp hardware improvement cpu gpu text summarization shall get reliable information shared online increase every year people spending time internet text summarization widely used enhance user experience data delivery everincreasing research better method field natural language processing future complex work done using model layer using completely new architecture like pointer generator network etc help computer understand natural language like never use various field reference gupta v lehal g survey text mining technique application journal emerging technology web intelligence ta kiyani f survey automatic text summarization press academia procedia allahyari pouriyeh assefi safaei trippe e gutierrez j b kochut k text summarization technique brief survey arxiv preprint arxiv nenkova mckeown k survey text summarization technique mining text data pp springer boston kanapala pal pamula r text summarization legal document survey artificial intelligence review wang l yao j tao zhong l liu w du q reinforced topicaware convolutional sequencetosequence model abstractive text summarization arxiv preprint arxiv kryscinski w mccann b xiong c socher r november evaluating factual consistency abstractive text summarization proceeding conference empirical method natural language processing emnlp pp song huang h ruan abstractive text summarization using lstmcnn based deep learning multimedia tool application ascus iop publishing iop conf series material science engineering doix cai h zheng v w chang k c c comprehensive survey graph embedding problem technique application ieee transaction knowledge data engineering kobayashi v b mol berkers h kismihk g den hartog n text mining organizational research organizational research method salloum alemran monem shaalan k using text mining technique extracting information research article intelligent natural language processing trend application pp springer cham qiang j qian z li yuan wu x short text topic modeling technique application performance survey ieee transaction knowledge data engineering"]}