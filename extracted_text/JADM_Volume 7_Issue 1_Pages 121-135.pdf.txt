Journal of AI and Data Mining
Vol 7, No 1, 2019, 121-135 DOI: 10.22044/JADM.2018.6139.1726
A survey on Automatic Text Summarization
N. Nazari and M. A. Mahdavi*
Department of computer engineering, Imam Khomeini International University, Qazvin, Iran.
Received 20 August 2017; Revised 14 November 2017; Accepted 05 February 2018
*Corresponding author: mahdavi@eng.ikiu.ac.ir(M. Mahdavi).
Abstract
Text summarization endeavors to produce a summary version of a text, while maintaining the original ideas.
The textual content on the web, in particular, is growing at an exponential rate. The ability to decipher
through such a massive amount of data to extract useful information is a significant undertaking, and
requires an automatic mechanism to aid with the extant repository of information. The text summarization
systems intent to assist with content reduction keeping the relevant information and filtering the non-relevant
parts of the text. In terms of the input, there are two fundamental approaches among the text summarization
systems. The first approach summarizes a single document. In other words, the system takes one document
as an input and produces a summary version as its output. An alternative approach is to take several
documents as its input and produce a single summary document as its output. In terms of output, the
summarization systems are also categorized into two major types. One approach would be to extract exact
sentences from the original document to build the summary output. An alternative would be a more complex
approach, in which the rendered text is a rephrased version of the original document. This paper will offer an
in-depth introduction to automatic text summarization. We also mention some evaluation techniques to
evaluate the quality of automatic text summarization.
Keywords: Automatic Text Summarization, Multiple Document Summarization, Single Document
Summarization, Summarization Evaluation Technique.
1. Introduction
the information in the original text(s), and is no
With the enormous amount of information
longer than half of the original text" [2].
generated every day, it is difficult to find the
desired information through the manual means. According to Mani [3], "text summarization is the
The World Wide Web provides a vast amount of process of extracting the most important
content in forms of web pages, news articles, information from a source (or sources) to produce
email, and access to the databases around the an abridged version for a particular user (or users)
world. However, much of this content may not be and task (or tasks)".
of use. Automatic text summarization has,
In terms of the building blocks and the structural
therefore, become a research field within the
components, an automatic text summarization
greater field of natural language processing to
process may be broken into three steps [4, 5]:
assist in finding the relevant documents [1]. The
goal of automatic text summarization is to extract  Identification: in this step, the main points
the main points of the original text without and central topics of the text are identified. In
needing to read the entire document. The its simple form, a summary is generated by
following definitions form the underlying gathering the important bits of the text.
assumptions regarding text summarization.
 Interpretation: the important topics that are
"A summary is a text that is produced from one or identified in the first step are combined more
more texts, and contains a significant portion of cohesively. During this step, someMahdavi & Nazari/ Journal of AI and Data Mining, Vol 7, No 1, 2019.
modifications to the original sentences may summary is generated by concatenating the
prove necessary. Additionally, a successful important parts of the text without modifying the
rendition of the text, in this step, may require original words and sentences. This is a simple and
domain knowledge. robust way of producing a summary. However, it
comes with the risk of producing an inconsistent
 Generation: the result of the second step is a
text since the selected sentences may not share a
summary that may not be coherent to the
semantic relation with one another. In other
reader. Therefore, the goal of this step is to
words, an extractive method may generate an
reformulate the extracted summary into a
incoherent summary [1].
coherent new text. The generation step is
In an abstractive summarization, the natural
where the final touches of editing are
language generation techniques are used to
performed to produce an understandable
perform the summarization task [12]. In this
summary for the reader.
method, one tries to understand the original
2. Various types of summaries document by identifying the key concepts and
There are different classifications for a summary then convert it into another semantic form, which
based on their input, output, purpose, and amounts to a shorter rephrased version of the
language [6], which we will elaborate in the original text [11, 13].
following sub-sections.
2.4. Summary based on content
2.1. Summary based on input Based on the content, a summary may be
In terms of input, a summary may be based on a customized according to the needs of the user. In
single document or multiple documents [7]. Early this respect, a summary may be categorized into
attempts in summarization were primarily based generic, query-based or domain specific. In a
upon single-document summarization, in which query-based summarization, the summary is
systems produced a summary from a single source generated by selecting a sentence that corresponds
document. However, later developments have to the user's query [14]. The sentences that are
ushered in text summarizations that are based on relevant to the query receive a higher chance to be
multiple source documents. In a multiple- extracted for the final summary. The query-based
document summarization, several documents that summarization systems, however, do not provide
share a similar topic are taken as the input. Given an overall view of the document's concepts since
the additional complexity to adjudicate among they focus on the user's query. The goal of the
several documents, the task of multiple-document generic summarization, on the other hand, is to
summarization is proportionally more difficult summarize the whole text without noticing the
than the single-document one. This is because the domain and subject [1]. Generic summaries do not
system would have to remove any redundancies have any view of the topic and consider the
across documents and also reconcile the contents document as a unique text, so all the information
into a coherent summary [8]. have the same level of importance [6]. Domain-
specific summarizers provide summary according
2.2. Summary based on details to the specific field [15]. In order to give a few
On the basis of its detail, a summary can be either examples, one may refer to summarizing business
indicative or informative. An indicative news articles [16], web pages [17], and
summarization system only presents the most biomedical documents [18], amongst many. This
important idea of the text. An indicative summary kind of summarization requires a domain-specific
gives an overall perspective of the topics covered knowledge to select sentences for summaries.
by the text. This type of summary helps the user
to decide on whether to read the text any further. 2.5. Summary based on language
The typical length of this kind of summary is On the basis of the language, there are three types
around 5 to 10 percent of the original text [1, 9]. of summaries: monolingual, multi-lingual, and
On the other hand, the informative summarization cross-lingual [1, 3]. In a mono-lingual
system covers every aspect of the main text. The summarization system, the language of source and
length of the informative summaries is around 20 target documents is the same. FarsiSum is a
to 30% of the original text [10]. monolingual text summarization system that
produces summary only for Persian text [19]. In a
2.3. Summary based on output multi-lingual summarization system, the source
Based on the generated text, a summary is either document and the generated summary could be in
extractive or abstractive [11]. An extractive some languages. SUMMARIST is a multi-lingual
122Mahdavi & Nazari/ Journal of AI and Data Mining, Vol 7, No 1, 2019.
text summarization system that is based upon an this method, Luhn emphasizes that the most
extraction method to produce summary from frequent words in the text represent the most
sources in different languages such as English, salient concepts within it. Thus word frequency is
Indonesian, Spanish, German, Japanese, Korean, used to score the sentences. By comparing scores
and French [20]. The cross-lingual summary is the of each sentence and extracting the sentence with
same as a multi-lingual one but the language of the highest score, the summary is generated.
source and target documents must be different. Baxendale [22] has investigated a machine
technique for summarization. He focused on the
3. Text summarization method position of the sentences, and explored that the
Much of the efforts made in the field of best location for the important content was the
summarization has been focused on improving the first and last parts of a paragraph. After examining
quality of the produced summary. So far, a 200 paragraphs, he came to this conclusion that in
catalog of different methods has been applied to 85% of them, topic sentences were in the first part
perform the summarization tasks mentioned in of the paragraph, and only in 7% of them they
Section 1. In this section, we would like to shed appeared in the last part.
light on various computational methods employed Edmunson [23] has introduced a method for
in summarization systems. While the approach to extracting sentences, which not only uses word
solve the summarization problem may vary from frequency but also considers the following three
one study to another, the general methods may be features:
categorized into four categories of statistical,
machine learning, semantic-based, and artificial 1. Cue phrases: this feature mentions that the
intelligent-based methods. Figure 1 gives a presence or absence of some cue words or
hierarchical view of the text summarization phrases such as "as a result," "for example,"
methods. and "as a matter of fact" indicates the
importance of the sentences that include these
text summarization phrases.
method
2. Title words: this feature predicts that words
appearing in the title of a document are
immediately relevant to the concepts outlined
in the text. Therefore, these words are viewed
machine semantic swarm as a factor to identify the important sentence.
statistical
learning based intelligence
3. Sentence location: this feature indicates that
the location of a sentence in the paragraph
particle
Cue phrase Naive Bayes lexical chain reveals its importance to the topic of the
swarm
paragraph. For instance, sentences that occur
in the initial part of a paragraph carry more
cuckoo
title words ANN clustering
optimization information than the rest of the paragraph.
Therefore, initial sentences of each paragraph
are potentially relevant candidates for
sentence bacterial
fuzzy logic graph based
location foragine sentence selection in a document summary.
Figure 1: Diagram of text summarization methods
The final score is computed by the linear
combination of four features. Edmundson
examined this method on 400 documents. The
3.1. Statistical method
results obtained indicated that considering the cue
This method deals with some statistical features of
words, title words, and sentence location would
the text to identify the prominent parts of a
produce a higher qualified summary than when
document. The goal of the statistical method is to
only the word frequency feature was applied. In
select sentences according to the physical
fact, he demonstrated that using word frequency
features, not the meaning or the relation of words
by itself yielded the worst result.
or sentences. Some of the statistical features are
Statistical methods are simple to carry out since
word frequency, position of the sentence, and
they only consider the physical feature of the text.
keywords. This section will cover some of these
However, these methods do not engage in the
statistical features.
meaning of sentences and words, which may
Word frequency is the number of times a word
produce a low-quality summary.
occurs in a text. Luhn [21] has used word
frequency for summarizing scientific articles. In
123Mahdavi & Nazari/ Journal of AI and Data Mining, Vol 7, No 1, 2019.
3.2. Machine learning method determined. In training the machine, the following
The idea behind machine learning is to use a seven features are considered:
training set of data to train the summarization
1. Paragraph follows title
system, which is modeled as a classification
problem. Sentences are classified into two groups: 2. Paragraph location in document
summary sentences and non-summary sentences
3. Sentence location in paragraph
[24]. The probability of choosing a sentence for a
summary is estimated according to the training 4. First sentence of paragraph
document and extractive summaries [25]. Some of
5. Sentence length
the common machine learning methods used for
text summarization are naïve Bayes, artificial 6. Number of thematic words in the sentence
neural network, and fuzzy logic [26, 27].
7. Number of title words in the sentence
3.2.1. Naïve Bayes method This step consists of two phases: 1) removing
Naïve Bayes is a supervised learning method. In uncommon features, and 2) removing the effects
text summarization, the naïve Bayes of common features. Therefore, this step
classification, introduced by Kupiec et al. [28], generalizes the important features that must exist
considers the selection of a sentence as a in the summary sentences. After the training and
classification problem. By this classification, each generalizing the network, this system can be used
sentence is put in a binary class to determine to select important sentences for the summary.
whether it will be included in the summary or not.
3.2.3. Fuzzy logic method
The features that are used in this method are word
Fuzzy logic is a multiple-valued logic and an
frequency, uppercase words, length of sentence,
extension of Boolean logic, which was introduced
position in paragraph, and structure of phrase. By
by Lotfi Zadeh [30] for describing the
considering k features and using the Bayes rule,
intermediate values between two discrete values
the probability that sentence s is included in
like "one" and "zero," and "high" and "low". The
summary S is defined as follows:
advantage of fuzzy logic is the compatibility with
the real world, which is not a two-value world.
k P(F |sS)P(sS) (1) For example, when describing the weather
P(sS |F,F,...,F ) j1 j
1 2 k k P(F ) condition, different adjectives such as cold, very
j1 j
where, P(sS)is a constant, P(F |sS) and cold, warm, hot, and very hot are used in fuzzy
j
logic rather than just using the two value of the
P(F ), are estimated from the training data. Here,
j Boolean logic. He used the fuzzy logic for the
a score is assigned to each one of the sentences.
natural language processing, which is called
Then this score is used towards selecting
computing with the word. The focus of this
sentences that would form the summary. Based on
research work was to enable the computer to
this score, the top n sentences are extracted, and a
understand the human language that was beyond
summary is produced.
the concept of one and zero, and could not be
implemented by the Boolean logic. In the
3.2.2. Artificial neural network method
computer, to process the human language, "the
The artificial neural network is a computational
objects of computation are words and propositions
model used in computer science and other
drawn from a natural language" [31].
research areas for solving problems based on
machine learning approaches. Kaikhah et al. [29] The concept of fuzzy logic can be used in text
used artificial neural networks for summarizing summarization, which is a branch of natural
news articles as a way to select sentences in an language processing to help to extract the
extractive summarization. There are three phases sentences [32]. Before using fuzzy logic, a pre-
of the proposed approach: neural network processing step was applied to the input text to
training, feature fusion, and sentence selection. make the text suitable for the fuzzy logic system
The training phase identifies the types of that included stopping word removal, stemming,
sentences that should be presented in the POS tagging, and so on. Then several features of
document summary. A human reader does this, each sentence like title feature, sentence length,
and the system learns the pattern of summary and term weight, among others, were considered.
sentences. After training the artificial neural Then the required rules were inserted in the
network, the relation among features should be knowledge base of this system. Afterward, a value
from 0 to 1 was obtained for each sentence in the
output based on sentence characteristics and the
124Mahdavi & Nazari/ Journal of AI and Data Mining, Vol 7, No 1, 2019.
available rules in the knowledge base. The value developed in this approach, which will be
obtained in the output determined the degree of the explained in the following sections.
importance of the sentence to be present or absent
in the final summary. 3.3.1. Lexical chain method
The lexical chain is a sequence of words in a
In another study by Hannah et al., which used
document that are semantically related to one
fuzzy logic for summarization, the same procedure
another. This method includes three steps, text
was used. Seven features of sentences were
segmentation, lexical chain identification, and
extracted [33]. The values for the extracted
finally, finding the strongest lexical chain for
features were given to fuzzy inference system and
sentence extraction [36]. After segmenting the
fuzzified to identify the important sentences.
sentences of a document, the words that are
Based on the importance of a sentence, the fuzzy
related semantically are identified, and relevant
system defuzzified sentences into one of the three
word chains are generated. For identifying a
variables named unimportant, average, and
lexical chain, WordNet is used. WordNet is used
important, which were used in selecting sentences
for determining words that belong to the same
for the summary. The summary was generated by
synset (synonym set). That is to say, words that
the sentences that were ranked important. Provided
occur within the same synset in the WordNet are
that the summary size was not satisfactory,
also semantically related to one another. The
sentences with an average rank were used as well.
semantic relation between words is represented by
However, unimportant sentences were never used
synonym, hyponym, and meronym [37]. A
for summary [33].
procedure for constructing lexical chains follows
The results obtained were compared with the three steps. These steps are as follow:
Microsoft summarizer to evaluate the performance 1. Select a set of candidate words;
of this method. In order to perform a comparison 2. For each candidate word, find an
task, 55 documents from DUC2002 were selected. appropriate chain relying on a relatedness
The fuzzy system produced an average precision criterion among members of the chains;
of 0.47, an average recall of 0.49, and an average 3. If it is found, insert the word in the chain
F-measure of 0.48. Compared with the Microsoft and update it accordingly.
summarizer with the 0.46, 0.39, and 0.42 At the end, the strong chains are selected
precision, recall, and F-measure, the fuzzy system towards constructing the final summary. In
had a better performance [33]. order to find the strong chain, each chain is
scored. The length and homogeneity index are
Machine learning method is effective in learning
used as two parameters to score the chains.
the features that are essential to make a summary
The length is calculated as some words in the
but there should be a training corpus to learn from
chain, and the homogeneity index is 1- the
it, so the training corpus is different from
number of distinct words divided by the
language to language and is not fixed for every
length. The final score of a chain is computed
document.
as the product of these two parameters. The
following criterion is used to select the strong
3.3. Semantic-based method
chain:
When it comes to summarization, statistical
Score (Chain) > Average (Score) + 2 * Standard
features are not all effective across the board
Deviation (Score)
because some features depend on the specific
The chains whose scores exceeded the above
format and the writing style of the documents
criterion are considered as strong chains. Then
[34]. For example, in title word, the problem is
sentences with the strong chain are selected to
that a document may not have a title. It may also
form the final summary. In order to evaluate the
happen that all the frequent words are not as
performance of this method, Nenkova and
important as lesser frequent words, in which case,
McKewon [6] compared the results with
ignoring words with less occurrence would
Microsoft summarizer on the documents that were
provide an unqualified summary. Semantic-based
selected from TREC collection and used the
methods identify the relationship between words
precision and the recall measures. The result
and sentences by use of a thesaurus, part-of-
precision and recall for lexical chain were 47 and
speech tagging, grammar analysis, and selection
64, respectively, for 20% of the input text. In
of meaningful sentences to generate summary
comparison with Microsoft summarizer, which
[35]. Various techniques like lexical chain,
had the precision and recall of 32 and 39, the
clustering, and graph-based methods have been
lexical chain had a better performance. It has to be
125Mahdavi & Nazari/ Journal of AI and Data Mining, Vol 7, No 1, 2019.
mentioned that a lexical chain considers the with other clusters but the components of the
relationship between words instead of just cluster have the most likeness with each other
focusing on the occurrence of the word. However, [40]. As the number of sentences in the cluster
it is heavily dependent on the WordNet that is increases, the importance of the information
constructed by human [6]. contained within the cluster increases. After
grouping the sentences in some clusters, from
The lexical chain was also utilized by Saxena
each cluster, a sentence is selected to produce an
[38] for text summarization, where the following
extracted summary. These sentences can be
formula was presented for a stronger lexical chain:
chosen using simple positional features.
Sarkar [41] considered four steps for the task of
Length (LC) = total number of particular (2)
clustering sentences. These steps are pre-
chain members (candidate words)
processing, sentence clustering, cluster ordering,
and selecting representative sentences from
clusters. In the pre-processing step, stop word
Length(LC) log2length(LC) (3)
Sig(LC) * removal, tokenization, and stemming are done.
 length(l)  length(l)
lD lD For clustering sentences, the similarity between
sentences should be measured to group similar
where, LC is a lexical chain; D, is the document; sentences in a cluster; to do this task, a uni-gram
l, is each chain in document D, and Sig, is the matching-based similarity measure is used, which
significance of lexical chain in the document. is defined as follows:
Related (w, LC) = 1 if (4) sim(S ,S )(2*|S I S |)/(|S ||S |) (7)
i j i j i j
they are related
= 0 if
where, S and S are two sentences; |S I S |
they are not related i j i j
shows the number of matching words between
The above formula is the relation equation that two sentences, and |S |is the length of sentence
i
shows if a word w is in the lexical chain LC or S .
not. i
After clustering sentences, clusters are ordered,
and clusters that have more important words get a
Utility(LC,D)sig(LC)* related(w,LC) (5)
wD high rank. The following equation is used to
compute a rank for clusters:
The Utility function shows the contribution of the
lexical chain in the document. weightof aclusterC,W (C)log(1count(w)) (8)
wC
Score Chain (L) = AVG + 2 * STD. Dev (6) where, count(w) represents the count of the word
w. for selection of representative sentences, the
where, AVG is the average of scores of lexical author used the method of local and global
chain (utility of each chain), and STD. Dev is the important word of a sentence. The local
standard deviation of the utility scores of each importance shows the importance of words in a
lexical chain. topic of the cluster but the global importance is
the importance of the word on multiple topics.
Lexical chain LC will be considered as a strong The importance of a sentence is calculated as
chain if Utility (LC) > Score Chain (L). follows:
Evaluation of the results of this method, which is Score(S) Weight(w) (9)
done by the Rouge tool, gives the average wS
precision of 0.45 and the average recall of 0.54.
Weight(w)log(1CTF)log(1CF)) (10)
1 2
3.3.2. Clustering method
In a clustering method, similar textual units (such
where,  and  are set to 0.5, Weight (w) shows
as words, sentences or paragraph) are clustered 1 2
together to identify the common information the importance of the word w, CTF (cluster term
between them [39]. Each cluster is known as a frequency) represents the count of a word in the
sub-domain of the content, with less similarity cluster, and log(1+CTF) is used for the local
importance of a word. CF (cluster frequency)
126Mahdavi & Nazari/ Journal of AI and Data Mining, Vol 7, No 1, 2019.
shows the number of clusters that contain the in the next section, the graph-based approach does
word, and log(1+CF) is used to calculate the not suffer from this side-effect.
global importance of a word. After ordering
3.3.3. Graph-based method
clusters and selecting representative sentences, the
In the field of natural language processing, graphs
summary is generated.
are used to display the structure of the text and the
For clustering multiple documents, a method has connection between sentences. Sentences are
been introduced by Gupta [11], which has 4 steps: represented as a node, and the relation between
pre-processing for preparing the input text, feature sentences are depicted by edges [43]. The graph-
extraction to select features based on the output based text summarization method is a technique to
summary feature, single-document summarization extract a significant, appropriate, and informative
whose sentences are clustered in each document, text in a compressed version [44]. In order to use
and the final steps of multi-document this technique, a pre-processing phase should be
summarization; a sentence from each cluster is done on the input text to remove stop words,
extracted to generate summary. The result of tokenize the sentences, and so on. Then sentences
testing this method on the DUC 2002 had the are ranked to identify the important sentences.
precision of 0.34, recall of 0.33, and F-measure of Afterward, the relation between sentences is
0.33. computed to recognize the relevant sentences. At
the end, sentences are extracted for the summary
Another work on text summarization based on
based on the ranked and relevant sentences.
clustering has been done by Deshpande and Lobo
Kumar et al. [45] used the graph-based technique
[42]. The proposed approach is a multi-document
to summarize Hindi texts. The TF-IDF (Term
system that is also query-based. In their study, they
Frequency-Inverse Document Frequency) method
used a collection of different documents and
is used to identify the important sentences and
queries as input. Subsequently, similar documents
rank them. Since the TF-IDF method is used for
were clustered into one group. For every
multi-document, the normalized term is frequency
document, the sentences were then clustered into
applied for scoring sentences that are defined as
sentence clusters. For scoring a sentence, several
follows:
features such as noun feature, cue phrase, sentence
length, numerical data, sentence location, sentence tf (11)
TF (1)*
centrality, uppercase word, and sentence similarity noun tf
max
with the user query are used. In this approach,
TF*IDF is used to score sentences. The cosine where, is between 0 and 1. In order to find the
similarity is used to find the similarity between
relevant sentences, similar sentences should be
sentences and queries. Sentences in each document
identified, so the cosine similarity is used to
cluster are clustered into sentence clusters based
compute the similarity between two sentences, and
on the similarity value. After scoring each
is defined as (12):
sentence, high scored sentences are selected to
form the final summary. The evaluation results n
x *y
(12)
show that the proposed method has the values of cos i1 i i
0.59, 0.49, and 0.51 for precision, recall and F-   n x 2* n y 2  
score, respectively. Comparing this method with  i1 i i1 i 
the statistical feature-based method, which yielded
0.49, 0.49, and 0.49, respectively, and the If two sentences are semantically similar, there
document clustering method with yields of 0.41, should be a connection between them. Extracting
0.3, and 0.32 for precision, recall, and F-score, the sentences for generating a summary is done based
proposed method outperforms these two methods. on the above two equations; sentences with high
ranks and all their relevant sentences are extracted
The clustering method is very useful for multiple-
and put together to produce a summary based on
document summarization since different sentences
the order of input document.
with the same topic in the documents are grouped,
and repeated sentences are avoided to be included By testing and analyzing this technique on a
in the summary. The drawback of the clustering different document, with a 60% compression rate,
method is that each sentence or paragraph is the average Recall, Precision, and F-measure were
assigned to only one cluster but some sentences 66.67%, 77.78%, and 70%, respectively.
express more than one topic, and should not be
A recent graph-based text summarization has been
restricted to one subject [6]. As it will be discussed
done by Natesh et al. [46]. In this approach, a pre-
127Mahdavi & Nazari/ Journal of AI and Data Mining, Vol 7, No 1, 2019.
processing phase is done on the text including particle swarm optimization, cuckoo optimization
tokenizing, part of speech tagging, and pronoun algorithm, and bacterial foraging optimization
resolution. After simplifying the text, a graph is along with their usage in text summarization will
built, in which the nodes are the representation of be explained.
nouns, and the weight of each edge connecting two
nodes is used to show the relevance between two 3.4.1. Particle swarm optimization
nouns. Then the distance between two nouns is The particle swarm optimization algorithm is an
computed as follows: evolutionary one, which has been introduced for
solving an optimization problem [54]. This
algorithm is based upon the social movement of
Distance(n1, n2)=|position(n1)- (13)
birds, and starts with a population of birds to
position(n2)|
discover the search space. Every individual in a
The edge weight is computed as follows: population has a random position and a velocity
that is dynamically adjusted not only by the
Edge_weight(n1,n2)=1/(1+(distance(n1,n2)) (14 information of its own experience but also by the
) ) local knowledge of its neighbors [55]. The best
position found by a particle as well as the best
n1 and n2 are nouns. position found by all particles are kept in the
memory. The next position and velocity of each
In order to score the sentences, the following
particle to reach the best value will be updated
equation is calculated:
according to the following equations:
SentenceScoresnsrelevence(n) (15) V (t 1)w *V (t)c r(p (t)x (t)) (17)
id id 1 1 id id
c r (p (t)x (t))
relevence(n)Ni 0edgeWeight(n,i) (16) 2 2 gd id
p is the best local solution found by the i-th
id
where, n is a noun, N is the total number of nouns,
particle, p is the best global solution found by
and s is the sentence. After calculating the gd
all particles, V (t)is the velocity of a particle at
sentence score, the sentences with a high score are id
chosen for the summary. time t, r and r are random numbers between
1 2
[0,1], c and c are acceleration parameters, and W
Rouge-1 is used for evaluating the summary; it had 1 2
is the inertia weight whose value is between
the average precision of 0.33, recall of 0.33, and F-
[0.4,0.9] [56].
score of 0.33.
Semantic-based methods are useful since they x (t 1)x (t)V (t 1) (18)
consider the meaning of each sentence and word id id id
that make a coherent and meaningful summary but
using these techniques are time-consuming and x (t 1)is the next position, x (t)is the current
id id
require more efforts than the other techniques. position, and V (t 1) is the new velocity that is
id
3.4. Swarm intelligence-based method obtained from (2).
In a computational context, a swarm is a group of
Particle swarm optimization has been used to solve
simple agents that have a collective behavior to
various problems. Some of its usages are in
perform a complex task by acting as a community
clustering [57, 55], scheduling [58], and data
[47]. The social behavior of ants, termites, bees,
mining [59], amongst others.
and other social beings have motivated
researchers to discover their lifestyle. Swarm Particle swarm optimization has also been used in
intelligence is also a branch of artificial text summarization by Binwahlan [60] for scoring
intelligence, which is based upon computer the sentences to generate summary with a high
simulation to copy the creature's interactions with match to human's summary. There are 3 phases in
each other and with their environment to solve an this work: feature selection, PSO encoding, and
optimization problem [48]. Various algorithms evaluation function. The first five features are
based on the swarm intelligence behavior have extracted, and in the PSO encoding step, the
been introduced for the problems of optimization position of each particle is represented by a bit,
[49], robotic [50], routing [51], data mining [52], corresponding to a feature and has the value 0 or 1.
clustering [53], and so on. In the following If the value of a bit is 1, it means that the
sections, some swarm-based algorithms such as corresponding feature is selected; in the case of 0
128Mahdavi & Nazari/ Journal of AI and Data Mining, Vol 7, No 1, 2019.
value of a bit, the corresponding feature is not case, a host bird either throws the egg away
selected. Then for each sentence, a score is or abandons the nest.
computed as follows:
The chicks grow up and become mature cuckoo
5 (19) birds. The mature cuckoos make some
Score(s )s(f )vopp(i)
i j communities and search the space to find the best
j1
environment for breeding and reproduction.
where, Score(s ) is the score of the sentence s , Finally, they converge to a location in which a
i i maximum number of cuckoo birds can survive
s(f )is the score of the j-th feature, and vopp(i) is
i [63]. This location is also known as a global
the value of the i-th bit in the particle position. The
maximum of the objective function. When flying
sentences are ranked in the descending order of
toward the goal habitat, the cuckoos do not fly the
their scores, and the n top sentences are selected
entire path. They fly λ% of the destination and
for the summary. The resulting summary is
with a deviation of φ radians (Figure 2) [64]. λ is a
evaluated by a fitness function, which shows that
random number between 0 and 1, and φ is a
pbest is the best-generated summary by a particle
number between /6,/6. These two
and gbest is the best-generated summary by all
parameters help the cuckoo bird to search for more
particles. These two values are used to change the
space.
position of each particle. After each iteration, the
position of the particle with the gbest value is
selected as a vector for the best-selected features.
Then the feature weights of all data collections are New
calculated to compute the final feature weights. habitat Goal
point
The performance of this algorithm was compared λ
to MS WORD using the Rouge software. The
φ
documents of Doc. 2002 including d105g, d070f, d
Group 3
d067f, and d061j were used to evaluate the task.
The F-Score results for performing the PSO
algorithm on the document are 0.42869, 0.44637,
Group 1
0.40616, and 0.39517, respectively, and the results
of MS WORD are 0.41201, 0.36625, 0.38179, and Group 2
0.32773. Comparison of the results shows that the
PSO algorithm has a better performance [61].
Figure 2. Movement of a cuckoo toward goal habitat
.
[64].
3.4.2. Cuckoo optimization algorithm
Cuckoo optimization is an evolutionary algorithm The cuckoo search optimization algorithm was
proposed by Yang and Deb [62] for finding an used for text summarization by Mirshojaei and
optimal solution. This algorithm is inspired by the Masoomi [61] to improve the performance of
behavior of cuckoo bird in laying eggs. To extractive summarization techniques. The
increase the chances of her egg survival, cuckoo proposed method has four steps. The first entails a
bird lays her eggs in the nest of other birds. Some pre-processing on input document, then a score is
eggs are discovered by the host bird and are assigned to a sentence by the weighting method.
thrown out. Eggs that are similar to the host bird's Afterward, the similarity between sentences and
egg, on the other hand, have the chance to be keyword is obtained using a similarity matrix.
hatched and grow up. There are three general Then the cuckoo search optimization algorithm is
rules for this algorithm, which are as follow [62]: applied to extract the important sentences, which
 Each cuckoo lays one egg at a time, and include five steps [61]:
leaves its egg in the nest that is chosen
1. The CSOA parameters are initialized;
randomly;
2. The sentences are assigned to birds
 The nest with a high quality of eggs is
randomly;
known as the best nest and will be
3. The assessment of birds is done based on
transferred to the next generations;
cost function;
 The number of available host nests is fixed,
and a host can discover an alien egg. In this 4. The position of birds is updated;
129Mahdavi & Nazari/ Journal of AI and Data Mining, Vol 7, No 1, 2019.
5. The end condition of loops is checked, if it  Elimination-dispersal: some temporal
is satisfied, the algorithm is finished; and sudden situations may kill the
otherwise, return to step 3.
bacteria. Some bacteria may also be
The cost function is used to compute the sentence moved to other places. Some bacteria
coherence and readability, and is as follows: are killed and some others are
initialized randomly to simulate this
log(C*91) situation.
CF 
s log(M *91) (20)
This algorithm was used for automatic text
 W (s ,s ) summarization by Dastkhosh Nikoo et al. [66].
C  Si,SjSummarySubgraph i j For doing the task of summarization, the weight is
s N assigned to each word of a sentence by a
s
weighting method. Then by summing over the
word's weight, a sentence score is achieved.
R (21)
RF  s , R  W (s ,s ) According to this score, sentences are stored in a
s max R s i i1
i i 0is descending order. Each word in a sentence is
represented by a bit that has the value of 0 or 1. If
where, CF is the coherence factor of sentences, the value is 1, it means that the term is selected for
s
C is the average similarity of available sentences the summary; in the case of 0 value, the term is not
s
in summarization, and M is the maximum weight chosen for the summary. After ordering sentences,
of sentences. RF is the readability factor of a according to bit mapping, each bacterium selects
s
the word to be in the document summary. The
summary with the length of s.
generated summary is evaluated by a fitness
The F-Score result of this algorithm in comparison function. This process is continued until the
with PSO algorithm and MS WORD on d105g, bacterial value converges to the threshold value.
d070f, d067f, and d061j are 0.49761, 0.46476,
By performing this algorithm for the task of
0.47128 and 0.42391, respectively, which show a
summarization on the d105g, d070f, d067f, and
better performance in performing the cuckoo
d061j documents of the Doc. 2002, the F-measure
search algorithm in text summarization [61].
results were 0.43543, 0.44126, 0.41765 and
3.4.3. Bacterial foraging optimization 0.39121. In comparison with MS WORD, PSO,
algorithm and cuckoo search algorithm, BFOA had a better
The bacterial foraging optimization algorithm is performance than MS WORD and PSO but
an optimization algorithm, which is inspired by cuckoo search algorithm performed better than
the social behavior of E. Coli bacteria in the body, BFOA [61].
proposed by Passino [65]. This algorithm consists
To give a comprehensive view of different
of 3 steps, which are defined as follow:
automatic text summarization methods and a
 Chemotaxis: this step simulates the
comparison of their results after testing on various
movement of bacteria in the state of swim
documents, also the advantages and disadvantages,
and tumble, and is calculated as follows:
we collected the results in table 1.
(i ) (
i(j1,k,l)i(j,k,l)C(i) The swarm-based summarization technique gives a
 T()(l2)
valuable summary when the length of the text is
2
long. Performing these methods is done in a
) shorter time compared to the other summarization
 methods.
 Where,i(j,k,l) represents the 4. Evaluation techniques
location of i-th bacteria in j-th In order to evaluate an automatic text summary, it
is the content of the summary that ought to be
chemotaxis, k-th reproduction, and l-th
evaluated. Several metrics have been introduced
elimination-dispersal step, and C(i) is
so far to achieve this goal. There are two general
the size of chemotaxis.
categories of evaluation metrics: intrinsic and
 Reproduction: the weak bacteria are
extrinsic [6]. The main aim of intrinsic metrics is
destroyed, and the strong bacteria are
to evaluate the performance of an automated
divided into two bacteria; this helps to summary content by comparing it with an ideal
balance the population of bacteria. summary. There are two measures for intrinsic
130Mahdavi & Nazari/ Journal of AI and Data Mining, Vol 7, No 1, 2019.
metric. The first measure involves quality intersection between the relevant and retrieved
evaluation, which tries to check that the summary sentences, divided by all the relevant sentences. F-
does not have grammatical errors, does not measure is an average of precision and recall
contain redundant information, and the produced criteria, and determines the score of the final set
summary possesses structural coherence. The of the selected sentences in a produced summary.
second measure is the content evaluation metric. relevantsentecesI retrievedsentences (23)
precision
Content evaluation metrics are divided into two retrievedsentences
groups: one is co-selection measure and the other
is content-based metric. relevantsentecesI retrievedsentences (24)
recall 
The co-selection measure shows the number of
relevantsentences
ideal sentences contained within an automatic
summary. The co-selection measure consists of a
2precisionrecall (25)
precision, recall, and F-measure [67]. Precision is Fmeasure 
precisionrecall
computed by the intersection of summarized
extracted, and ideal sentences, divided by all
extracted sentences. The recall is computed by the
Table 1:. Comparison between different methods.
Name of method List of the studies Advantages Disadvantages Recall Precision F-measure
Luhn (word Simple to perform Do not consider the
Statistical method frequency) meaning of the - - -
Baxendale (location word depending on
method) the text format
Edmundson (cue
phrase, title words,
and sentence
location)
Kupiec (naïve By utilization of Dependence on the
Machine learning Bayes method) various machine training dataset 0.47 0.49 0.48
method Kyoomarsi (fuzzy learning algorithms, Complexity in
logic) comprehensive computation
Kaikhah (artificial summary is
neural network) produced
Brazilly and Consider Word
Elhadad (lexical sense Dependence on the 64 47 -
chain method) disambiguation that WordNet
has a multiple
Semantic-based meaning
method Sarkar (sentence Reduces
clustering) redundancy in Limits each 0.34 0.33 0.33
Gupta (multi- multi-document sentence to be put
document summarization; it is only in one cluster
summarization) appropriate for the
domain-specific
summarization
Kumer (graph-based Consider different Complexity in
method) meanings of measurement 77.78 66.67 70
sentences
Binwahllan (particle Consider each Stick to the local
swarm optimization) feature of text fairly minima and has - - 0.44
based on their early convergence
Swarm importance
intelligence based Mirshojaei et al. Better performance
method (Cuckoo search compared with - - - 0.46
optimization other methods
method)
Dastkhosh Nikoo et
al. (Bacterial - - - - 0.44
foraging
optimization
method)
 Cosine similarity: by having the two vectors
ur ur
Content-based metrics are computed as follow: z and y , cosine similarity measures the
angle between these two vectors [68, 69].
131Mahdavi & Nazari/ Journal of AI and Data Mining, Vol 7, No 1, 2019.
Supposing that X and Y are the automatic methods were introduced, which could be used to
text summary and the reference summary, examine and compare the results of different
respectively, the cosine similarity for these approaches. By comparing different methods of
two summaries is calculated as follows: summarization, we came into this conclusion that
by utilizing different methods in a hybrid way, the
 x .y (26) quality of summary would be more effective since
cos(X ,Y ) i i i
combining two methods, for example, causes to
 (x )2.  (y )2
i i i i eliminate their shortcomings and use their
strength to improve the quality of the proposed
 Unit overlap [69]: the overlap between two
hybrid method. Also the combination of different
units (vocabulary, phrase or other textual
features of the document often produces better
units) of text is calculated as follows:
results when assigning weights to sentences.
X IY
(27)
overlap(X,Y )
X Y  X IY References
[1] Jezek, K. & Steinberger, J. (2008). Automatic text
where, X and Y are an automatic text
summarization, The state of the art 2007 and new
summary and a reference summary, challenges, in Proceedings of Znalosti, pp. 1-12.
respectively.
[2] Hovy, E. (2005). text summarization, In: R.
 ROUGE: Recall-Oriented Understudy for
Mitkov, Ed., The Oxford Handbook of Computational
Gisting Evaluation [70] evaluates summary
Linguistics, Oxford University Press, Oxford, pp. 583-
quality by comparing it with a human- 598.
generated summary. There are five
[3] Mani, I. (2001). Automatic Summarization. John
evaluation metrics in Rouge tool: ROUGE-N,
Benjamins Publishing Company, Philadelphia,
ROUGE-W, ROUGE-S, ROUGE-SU, and
Pennsylvania, U.S.A, pp. 1-286.
ROUGE-L. Rouge-n is computed as follows:
[4] Jones, K. S. ( 1999). Automatic summarization:
factors and directions. Advance in automatic text
  Count (gram ) (28)
Rougen CRSS gramnC match n summariztion, Springer, pp. 1-12.
  Count(gram )
CRSS gramnC n
[5] Hovy, E. & Lin, C. Y. (1999). Automated Text
Summarization in SUMMARIST. In I. Mani and
where, RSS denotes the reference summary, and
M.T.Maybury, eds., Advances in Automatic Text
Count (gram ) is the maximum number of n- Summarization, The MIT Press, pp.81–94.
match n
grams co-occurring in a generated summary and
[6] Nenkova, A. & McKeown, K. (2011). Automatic
reference summary. Also Count(gram n) is the
summarization. Foundations and Trends in Information
number of n-grams in the reference summary. Retrieval. vol. 5, no. 2-3, pp. 103-233.
The extrinsic evaluation metric is known as task- [7] Kumar, Y. J., Goh, O. S., Basiron, H., Choon, N. H.
oriented measures; question-answering, and & Suppiah, P. C. (2016). A Review on Automatic Text
information retrieval are instances of the extrinsic Summarization Approaches. Journal of Computer
method. Their goal is to evaluate a summary Science, vol. 4, no. 12, pp. 178-190.
performance based on a special task [6]. [8] Jade, G., Mittal, V., Carbonell, J. & Kantrowitz, M.
(2000). Multi-document summarization by sentence
5. Conclusion exraction. In proceeding of the 2000 NAACL-
By the progress in the production of a voluminous ANLPWorkshop on automatic summarization. Seattle,
Washington, pp. 40-48.
body of information due to the arrival of the
internet, automatic text summarization has [9] Saggion, H. & Lapalme, G. (2002). Generating
attracted a significant level of attention to ease the Indicative-Informative Summaries with SumUM.
task of providing necessary information for users. Computation of linguistic, vol. 28, no. 4, pp. 497-526.
Different kinds of summaries such as abstractive,
[10] Fan, W., Wallace, L. & Zhongj, S. R. (2005).
extractive, and single and multi-documents have Tapping into the Power of Text Mining.
been explained in this survey. Also various Communications of ACM, Vol. 49, No. 9, pp. 76-82.
summarization techniques like statistical, machine
[11] Gupta, V. & Lehal, S. L. (2010). A Survey of
learning, semantic-based, and swarm intelligence-
Text Summarization Extractive Techniques. Journal of
based method were described, whose focuses
emerging technologies in web intelligence, vol. 2, no.3,
were on the extractive summary since abstractive pp. 258-268.
summary needs complex natural language
[12] Cheung, J. (2008). Computing abstractive and
processing method. Finally, some evaluation
extractive summarization of evalutive text:
132Mahdavi & Nazari/ Journal of AI and Data Mining, Vol 7, No 1, 2019.
controversality and content selection. B. Sc. (Hons.)
University of British Columbia, pp. 1-38. [25] Othman, B., Haggag, M. & Belal, M. (2014). A
taxonomy for text summarization. Information Science
[13] Karmakar, S., Lad, T. & Chothani, H. (2015). A
and Technology, vol. 3, no. 1, pp. 43-50.
Review Paper on Extractive Techniques of Text
Summarization. International Research Journal of [26] Bharti, S. K., Babu, K. S. & Jena, S. K. (2017).
Computer Science (IRJCS), vol. 2, no. 1, pp. 18-21. Automatic keyword extraction for text summarization
in multi document e-newspapers article. European
[14] Gong, Y. & Liu, X. (2011). Generic Text
Journal of Advances in Engineering and Technology,
Summarization using Relevance Measure and Latent
vol. 4, no. 6, pp. 410-427.
Semantic Analysis. In Proceedings of the Annual.
International ACM SIGIR Conference on Research and [27] Gambhir, M. & Gupta, V. (2016). Recent
Development in Information Retrieval, New Orleans, automatic text summarization techniques: a survey.
Louisiana, USA, pp. 19-25. Artif. Intell. Rev. Springer Sci. Media Dordr., vol. 47,
no. 1, pp. 1–66.
[15] Kumar, C., Pingali, P. & Varma, V. (2008).
Generating Personalized Summaries Using Publicly [28] Kupiec, J., Pedersen, J. & Chen, F. (1995). A
Available Web Documents. in ACM International trainable document summarizer. In SIGIR '95
Conference on Web Intelligence and Intelligent Agent Proceedings of the 18th annual international ACM
Technology, IEEE Computer Society Washington, DC, SIGIR conference on Research and development in
USA, vol. 3, pp. 103-106. information retrieval, Seattle, Washington, USA, pp.
68-73.
[16] Wu, C. W. & Liu, C. L. (2003). Ontology-based
Text Summarization for Business News Articles. in [29] Kaikhah, K. (2004). Text Summarization Using
Proceedings of the ISCA Eighteenth International Neural Networks. In proceeding of second conference
Conference on Computers and Their Applications, pp. on intelligent system, IEEE, vol. 1, pp. 40-44.
389-392.
[30] Zadeh, L. (1965). Fuzzy Sets. information and
[17] Radev, D. R., Fan, W. & Zhang, Z (2001). control, vol.8, no.3, pp. 338-353.
WebInEssence: A Personalized Web-Based Multi-
[31] Zadeh, L. (1999). From Computing with Numbers
Document Summarization and Recommendation
to Computing with Words—From Manipulation of
System. NAACL Workshop on. Automatic
Measurements to Manipulation of Perceptions. IEEE
Summarization, pp. 79-88.
transaction on circuits and systems: fundamental theory
[18] Reeve, L. H., Han, H. & Brooks, A. D. (2007). and application, vol. 45, no. 1, pp. 105-119.
The use of domain-specific concepts in biomedical text
[32] Kyoomarsi, F., Khosravi, H., Eslami, E.,
summarization. Information Processing &
Dehkordy, P. K. & Tajoddin, A. (2008). Optimizing
Management, vol. 43, no. 6, pp. 1765–1776.
Text Summarization Based on Fuzzy Logic. in Seventh
[19] Hassel, M. & Mazdak, N. (2004). FarsiSum - A IEEE/ACIS International Conference on Computer and
Persian text summarizer. In the proceedings of Information Science, pp. 347-352.
Computational Approaches to Arabic Script-based
[33] Hannah, M. E., Geetha, T. & Mukhe, S. (2011).
Languages, Workshop at Coling 2004, the 20th
Automatic Extractive Text Summarization Based on
International Conference on Computational
Fuzzy Logic: A Sentence Oriented Approach.
Linguistics, pp. 82-84
Springer-Lecture Notes in Computer Science, pp. 530-
[20] Hovy, E. & Lin, C. Y. (1999). Automated Text 538.
Summarization in SUMMARIST. In Advances in
[34] Youngjoong, K. & Jungyun, S. (2008). An
Automatic Text Summarization, I. Mani and M.
effective sentence-extraction technique using
Maybury (editors), pp. 1-14.
contextual information and statistical approaches for
[21] Luhn, H. (1958). The Automatic Creation of text summarization. Pattern Recognition Letters, vol.
literature abstracts. IBM J. Res. Dev, pp. 159-165. 29, no. 9, pp. 1366–1371.
[22] Baxendale, P. B. (1958). Machine- Made Index [35] Chandra, M., Gupta, V. & Paul, S. K. (2011). A
for Technical Literature. An Experiment. IBM Journal Statistical approach for Automatic Text Summarization
of Research Development, vol. 4, no. 2, pp. 354-361. by Extraction. In 2011 International Conference on
Communication Systems and Network Technologies,
[23] Edmondson, H. P. (1969). New Methods in
pp. 268-271.
Automatic Extracting. Journal of the ACM, vol. 2, no.
16, pp. 264-285. [36] Barzilay, R. & Elhadad, M. (1997). Using Lexical
Chain for Text Summarization. In Proceeding of the
[24] Oak, R. (2016). Extractive Techniques for
ACL/EACL'97 Workshop on Intelligent Scalable Text
Automatic Document Summarization: A Survey.
Summarization, pp. 10-17.
International Journal of Innovative Research in
Computer and Communication Engineering, vol. 4, no. [37] Ranjan, P. A. & Saha, D. (2014). An approach to
3, pp. 4158-4164. automatic text summarization using WordNet. In
133Mahdavi & Nazari/ Journal of AI and Data Mining, Vol 7, No 1, 2019.
Advance Computing Conference (IACC), pp. 1169- [50] Beni, G. (2005). From Swarm Intelligence to
1173. Swarm Robotics. International Workshop on Swarm
Robotics, Springer, Berlin, Heidelberg, pp. 1-9.
[38] Saxena, S. & Saxena, A. (2016). An Efficient
Method based on Lexical Chains for Automatic Text [51] Saleem, M., Di Caro, G. A. & Farooq, M. (2011).
Summarization. International Journal of Computer Swarm intelligence based routing protocol for wireless
Applications, vol. 144, no. 1, pp. 47-52. sensor networks: Survey and future directions.
Information Sciences, vol. 181, no. 20, p. 4597–4624.
[39] Hatzivassiloglou, V., Klavans, J. L., Holcombe,
M. L., Barzilay, R., Kan, M. Y. & McKeown, K. R. [52] Grosan, C., Abraham, A. & Chis, M. (2006).
(2001). SIMFINDER: A flexible clustering tool for Swarm Intelligence in Data Mining, In Swarm
summarization. In proceeding of the NAACL Intelligence in Data Mining, Springer Berlin
Workshop on Automatic Summarization, pp. 41-49. Heidelberg, vol. 34, pp. 1-20.
[40] Khazaei, A. & Ghasemzadeh, M. (2015). [53] Ajith, A., Swagatam, D. & Sandip, R. (2008).
Comparing k-means clusters on parallel Persian- Swarm Intelligence Algorithms for Data Clustering. in
English corpus. Journal of AI and Data Mining, vol. 3, Soft Computing for Knowledge Discovery and Data
no. 2, pp. 203-208. Mining, Springer US, pp. 279-313.
[41] Sarkar, K. (2009). Sentence Clustering-based [54] Kennedy, J. & Eberhart, R. (1995). Particle
Summarization of Multiple Text Documents. Swarm Optimization, In proceeding of the IEEE
TECHNIA – International Journal of Computing international joint conference on neural networks, vol.
Science and Communication Technologies, vol. 2, no. 4, pp. 1942-1948.
1, pp. 325-335.
[55] Izakian, Z. & Mesgari, S. (2015). Fuzzy clustering
[42] Anjali, D. R. & Lobo, L. M. R. J. (2013). Text of time series data: A particle swarm optimization
Summarization using Clustering Technique. approach, Journal of AI and Data Mining, vol. 3, no. 1,
International Journal of Engineering Trends and pp. 39-46.
Technology (IJETT), vol. 4, no. 8, pp. 3348-3351.
[56] Eberhart, R. & Shi, Y. (2001). Particle swarm
[43] Ramesh, A., Srinivasa, K. G. & Pramod, N. optimization: Developments, applications and
(2014). SentenceRank- A graph based approach to resources. in proceedings of the 2001 Congress on
summarize text. In Application of Information and Evolutionary Computation, Seoul, pp. 81-86.
Web Technologies (ICADIWT), Bangalore, India, pp.
[57] Cura, T. (2012). A particle swarm optimization
177-182.
approach to clustering. Expert Systems with
[44] Mihalcea, R. & Tarau, P. (2005). A Language Applications: An International Journal, vol. 39, no. 1,
Independent Algorithm for Single and Multiple pp. 1582-1588.
Document Summarization. In Proceedings of the
[58] Pandey, S., Wu, L. & Guru, S. M. (2010). A
International Joint Conference on Natural Language
Particle Swarm Optimization-Based Heuristic for
Processing (IJCNLP), pp. 602-607.
Scheduling Workflow Applications in Cloud
[45] Kumar, K. V., Yadav, D. & Sharma, A. (2015). Computing Environments. The 24th IEEE Int. Conf. on
Graph Based Technique for Hindi Text Advanced Information Networking and Applications,
Summarization. Information Systems Design and pp. 400-407.
Intelligent Applications, vol. 339, pp. 301-310.
[59] Sousa, T., Silva, A. & Neves, A. (2004). Particle
[46] Natesh, A. A., Balekuttira, S. T. & Patil, A. P. Swarm based Data Mining Algorithms for
(2016). Graph Based Approach for Automatic Text classification tasks. Parallel Computing, vol. 30, no. 5-
Summarization. International Journal of Advanced 6, pp. 767–783.
Research in Computer and Communication
[60] Binwahlan, M. S., Salim, S. & Suanmali, S.
Engineering, vol. 5, no. 2, pp. 6-9.
(2009). Swarm Based Features Selection for Text
[47] Jarraya, B. & Bouri, A. (2012). Metaheuristic Summarization. IJCSNS International Journal of
Optimization Backgrounds: A Literature Review. Computer Science and Network Security, vol. 9, no. 1,
International Journal of Contemporary Business pp. 175-179.
Studies, vol. 3, no. 12, pp. 31-44.
[61] Mirshojaei, S. H. & Masoomi, B. (2015). Text
[48] Ajith, A., Swagatam, D. & Sandip, R. (2008). Summarization Using Cuckoo Search Optimization
Swarm Intelligence Algorithms for Data clustering. in Algorithm. Journal of Computer & Robotics, vol. 8,
Soft Computing for Knowledge Discovery and Data no. 2, pp. 19-24.
Mining, O. Maimon and L. Rokach, Eds., Springer US,
[62] Yang, X. S. & Deb, S. (2009). Cuckoo Search via
pp. 279-313.
L´evy Flights. in proceeding of World Congress on
Nature and Biologically Inspired Computing (NaBIC
[49] Bonabeau, E., Dorigo, M. & Theraulaz, G. (1999).
2009), pp. 210-214.
Swarm Intelligence: From Natural to Artificial Swarm
intelligence, Oxford University Press, pp. 1-320.
134Mahdavi & Nazari/ Journal of AI and Data Mining, Vol 7, No 1, 2019.
[63] Lashkari, M. & Moattar, M. (2017). Improved [68] Salton, G. (1988). Automatic text processing.
COA with Chaotic Initialization and Intelligent Addison-Wesley Longman Publishing Co., Inc.
Migration for Data Clustering. Journal of AI and Data Boston, MA, USA, pp. 1-523.
Mining, vol. 5, no. 2, pp. 293-305.
[69] Saggion, H., Radev, D., Teufel, S., Lam, W. &
[64] Rajabioun, R. (2011). Cuckoo Optimization Strassel, S. M. (2002). Developing Infrastructure for
Algorithm, Applied Soft Computing, vol. 11, no. 8, pp. the Evaluation of Single and Multi-Document
5508–5518. Summarization Systems in a Cross-Lingual
Environment. In Proceedings of LREC, Las Palmas,
[65] Passino, K. M. (2002). Biomimicry of bacterial
pp. 747-754.
foraging for distributed optimization and control, IEEE
control system magazine, vol. 22, no. 3, pp. 52-67. [70] Lin, C (2004). Rouge: A package for automatic
evaluation of summaries. In Text Summarization
[66] Nikoo, M. D., Faraahi, A., Hashemi, S. M. &
Branches Out: Proceedings of the ACL-04 Workshop,
Erfani, S. H. (2012). A Method for Text
vol. 8, pp. 74-81.4
Summarization by Bacterial Foraging Optimization
Algorithm, IJCSI International Journal of Computer
Science Issues, vol. 9, no. 4, pp. 36-40.
[67] Steinberger, J. & Jezek, K. (2009). Evaluation
measures for text summarization. In Computing and
Informatics, vol. 28, no. 2, pp. 1001-1028.
135یواک هداد و یع ونصم شوه یهرشن
نتم یزاسهصلاخ یرورم هلاقم
*یودهم نیمادمحم و یرظن نیرسن
.ناریا ،نیوزق ،)هر( ینیمخ ماما یلملا نیب هاگشناد ،یسدنهم ینف هدکشناد
0200/20/20 شریذپ ؛0202/00/20 یرگنزاب ؛0202/20/02 لاسرا
:هدیکچ
ووصخ هب ینتم یاوتحم دیلوت .ددرگیم ظفح دنیارف نیا رد نتم یلصا یاوتحم هک دشابیم نتم زا رتهاتوک یاهخسن دیلوت ینعم هب نتم یزاسهصلاخ
هوک وسا هدوش یدودت یوساسا شلاچ کی هب دانسا زا یمیظع مجح نیب زا دیفم تاعلاطا جارختسا .دشابیم شیازفا لاحرد زور هب زور بو تاحفص رد
طدترومریی یاوهشوخب ذوح و طدترم تاعلاطا ظفح اب هک دنیامنیم شلات نتم یزاسهصلاخ یاهمتسیس .دشابیم دنیارف نیا ندومن راکدوخ دنمزاین
یدنوس کوت یزاسهصلاخ هک ،لوا درکیور رد .دشابیم درکیور ود یاراد نتم یزاسهصلاخ متسیس کی ،یدورو ساسا رب .دیامن کمک دنیارف نیا هب نتم
رد .دویامنیوم دویلوت هوصلاخ کی و دریذپیم یدورو ناونع هب ار دنس کی متسیس ،رگید ترادع هب .دوشیم دیلوت دنس کی زا یاهصلاخ ،دوشیم هدیمان
-هوصلاخ ناوونع هب هک دیامنیم دیلوت دحاو هصلاخ کی و دریذپیم یدورو ناونع هب ار دشابیم ناسکی اهنآ عوضوم هک دنس نیدنچ متسیس ،مود درکیور
یاوههوصلاخ هوک لوا هتوسد .دنووشیوم میوسست هتوسد ود هب یزاسهصلاخ یاهمتسیس ،زین یجورخ ساسارب .دوشیم هتفرگ رظن رد یدنس دنچ یزاس
دویلوت هب نتم یلحت و یسررب اب مود هتسد .دزادرپیم هصلاخ دیلوت هب اهنآ نداد رارق مه رانک و یلصا نتم تلامج جارختسا اب هک ،دنشابیم یجارختسا
راوکدوخ یزاوسهوصلاخ یاوهمتسیس زا یخرب میراد دصق ،هلاسم نیا رد .دوشیم دیلوت یلصا نتم زا توافتم یتاملک و تلامج اب هک دزادرپیم یاهصلاخ
یوسررب زاوسهوصلاخ یاوهمتوسیس طسوت هدش دیلوت یاههصلاخ یفیک یبایزرا روظنم هب ار یبایزرا یاهصخاش زا یخرب نینچمه .مییامن رورم ار نتم
.مییامنیم
.هصلاخ یبایزرا یاهصخاش ،یدنس کت یزاسهصلاخ ،یدنسدنچ یزاسهصلاخ ،نتم راکدوخ یزاسهصلاخ :یدیلک تاملک