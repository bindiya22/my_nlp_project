3202
tcO
71
]LC.sc[
2v94401.0132:viXra
Text Summarization Using Large Language Models:
A Comparative Study of MPT-7b-instruct,
Falcon-7b-instruct, and OpenAI Chat-GPT Models
Lochan Basyal Mihir Sanghvi
Mentee, KaggleX BIPOC Mentorship Program Cohort 3 Mentor, KaggleX BIPOC Mentorship Program Cohort 3
bashyallochan@gmail.com mihir2891@gmail.com
Abstract—Text summarization is a critical Natural Language The ’text-davinci-003 (Legacy)’[1] model represents a re-
Processing (NLP) task with applications ranging from informa- markable leap in the field of Natural Language Processing
tionretrieval tocontent generation.Leveraging Large Language (NLP). It exhibits an unparalleled ability to handle a wide
Models (LLMs) has shown remarkable promise in enhancing
rangeoflanguagetaskswithexceptionalprecisionandquality.
summarizationtechniques.Thispaperembarksonanexploration
of text summarization with a diverse set of LLMs, including Notably, it surpasses its predecessors, including the Curie,
MPT-7b-instruct,falcon-7b-instruct,andOpenAIChatGPTtext- babbage,andAdamodels,intermsofgeneratingtextofhigher
davinci-003 models. The experiment was performed with differ- quality, offering longer outputs, and consistently following
ent hyperparameters and evaluated the generated summaries
providedinstructions. This legacymodelhas a token capacity
using widely accepted metrics such as the Bilingual Evalua-
of 4,097, enabling it to handle extensive text generation with
tion Understudy(BLEU) Score, Recall-Oriented Understudy for
Gisting Evaluation (ROUGE) Score, and Bidirectional Encoder ease. Moreover, ’text-davinci-003 (Legacy)’ introduces inno-
RepresentationsfromTransformers (BERT)Score.Accordingto vativefeatures,suchas the capabilityto inserttextseamlessly
the experiment, text-davinci-003 outperformed the others. This intogeneratedcontent,therebyexpandingitsutilityfordiverse
investigationinvolvedtwodistinctdatasets:CNNDailyMailand
text manipulation tasks.
XSum. Its primary objective was to provide a comprehensive
The’MPT-7B-Instruct’model,ascitedin[2],[3],is specifi-
understanding of the performance of Large Language Models
(LLMs) when applied to different datasets. The assessment callydesignedforshort-forminstruction-followingtasks,mak-
of these models’ effectiveness contributes valuable insights to ing it an ideal choice for a wide range of instruction-based
researchers and practitioners within the NLP domain. This applications. It is created through the fine-tuning process of
work serves as a resource for those interested in harnessing the
a base model, MPT-7B, using a dataset sourced from the
potentialofLLMsfortextsummarizationandlaysthefoundation
DatabricksDolly-15kandtheAnthropicHelpfulandHarmless
for the development of advanced Generative AI applications
aimed at addressing a wide spectrum of business challenges. (HH-RLHF) datasets. This tailored approach results in a
Index Terms—Text Summarization, MPT-7b-instruct, Falcon- model that excels at understandingand following instructions
7b-instruct, OpenAI ChatGPT with precision and accuracy. The model follows a modified
decoder-only transformer architecture, optimized for superior
performance in instruction-following tasks.
I. INTRODUCTION
Falcon-7B-Instruct’, as cited in[5], [6], represents a
IntheeraofBigData,theabundanceoftextualinformation formidable 7 billion-parameter causal decoder-only model
has underscored the importance of efficient text summariza- meticulously crafted by the Technology Innovation Institute
tion techniques. Text summarization, the task of distilling (TII).ThismodelisbuiltupontherobustfoundationofFalcon-
long documents or articles into concise, coherent summaries 7B and undergoes a fine-tuning process using a composite
while preserving the core meaning and essential information, datasetsourcedfrombothchatand instructdomains.’Falcon-
holds immense value across various domains. From aiding 7B-Instruct’ is generously made available under the Apache
in information retrieval to content generation, summarization 2.0 license.
has emerged as a pivotal component of Natural Language The focus of this paper is to delve into the world of
Processing (NLP) applications. text summarization with LLMs, offering a comprehensive
Recent advancements in NLP have been characterized exploration of their potential and limitations. Specifically, we
by the rise of Large Language Models (LLMs), OpenAI investigate various LLMs, experiment with different hyperpa-
ChatGPT[1], MPT-7b-instruct[2], [3], flan-t5-xl[4], falcon-7b- rameters, and evaluate the quality of summaries generated by
instruct[5], [6], and others, which have demonstrated remark- these models. To ensure a robust evaluation,we employwell-
able capabilities in understanding and generating human-like established metrics such as BLEU Score, Rouge Score, and
text. These LLMs have opened new avenues for text summa- Bert Score.
rization by providing powerfulgenerative capabilities and the This paper serves as a vital resource for those seeking to
ability to adapt to diverse tasks through fine-tuning. harnessthepowerofLLMsforNLPapplicationsandlaysthegroundwork for the development of advanced Generative AI B. Unsupervised Summarization
solutionstoaddressawiderangeofbusinesschallenges.Inthe
Unsupervised summarization, on the other hand, does not
followingsections,thepaperprovidesdetailedexplanationsof
require labeled training data. Instead, it seeks to extract
thetextsummarizationmethodsdiscussedinSectionII,super-
the most relevant information from the source text using
vised and unsupervisedsummarizationin Section III, datasets
algorithms that consider factors like sentence importance,
andevaluationmetricspresentedin SectionIV, inferencewith
coherence, and redundancy. Unsupervised methods are often
different LLMs in Section V, and offers a roadmap for future
employed when labeled summarization datasets are scarce or
enhancements,concluding with Section VI. Lastly, the author
costly to obtain.
acknowledges the support received during the research and
experiments. IV. DATASETSANDEVALUATION METRICS
In our study, we conducted experiments and evaluations
II. TEXTSUMMARIZATION METHODS on two distinct datasets, CNN/Daily Mail 3.0.0[7] and the
ExtremeSummarization(XSum)[8] to assess theperformance
Text summarization is a fundamental task in Natural Lan- of various Large Language Models (LLMs) in the context of
guage Processing (NLP) that aims to condense large volumes textsummarization.Thesedatasetsserveasthefoundationfor
of text into shorter, coherent representations while preserving our evaluationand comparisonof LLM-generatedsummaries.
the essential information.There are primarily two approaches
A. Datasets
to text summarization: abstractive and extractive summariza-
tion. • CNN/Daily Mail 3.0.0 Dataset: The CNN/Daily Mail
3.0.0 Dataset, a valuable resource in the realm of nat-
A. Abstractive Text Summarization ural language processing, comprises more than 300,000
unique news articles authored by journalists from CNN
Abstractive summarization involves generating a concise and the Daily Mail. Originally designed to facilitate ma-
summary that may contain words, phrases, or sentences not chine reading and comprehension, this English-language
presentinthesourcetext.Thisapproachreliesonunderstand- dataset has since evolved to support both extractive and
ingthecontextandgeneratinghuman-likelanguagetoconvey abstractive summarization tasks. The dataset provides
thecentralideas.Abstractivesummarizationmethodsoftenuse three key data fields for each entry: ’id,’ which contains
advanced language models, such as Large Language Models the hexadecimal-formattedSHA1 hash of the URL from
(LLMs), to rewrite and rephrase content in a more concise whichthestorywasretrieved;’article,’whichcontainsthe
form. bodyof the newsarticle itself; and’highlights,’featuring
the article’s highlights as written by the original author.
B. Extractive Text Summarization • XSum Dataset: XSum dataset is a valuable resource
tailored for extreme summarization tasks. It consists of
Extractivesummarization,on the other hand,aims to select
news articles with three key features: the ’document,’
and extract the most important sentences or phrases directly
servingastheinputnewsarticle,the’summary’providing
fromthe sourcetext to form the summary.It doesnotinvolve
aone-sentencesummaryofthearticle,andthe’id,’which
rephrasingorgeneratingnewsentences.Extractivesummariza-
uniquely identifies each article using the BBC ID.
tionmethodsuse varioustechniques,suchas sentencescoring
The inclusion of these diverse datasets allows us to evalu-
and ranking, to identify and extract the most salient content.
ate the performance of LLMs across various content types,
ensuring that our study provides a holistic view of their
III. SUPERVISED AND UNSUPERVISED SUMMARIZATION
summarization capabilities.
Text summarization techniques can be broadly categorized
B. Evaluation Metrics
into two main approaches based on dataset labeling: super-
To assess the quality and effectiveness of the generated
vised and unsupervisedsummarization.Each approachhas its
summaries, we employed a set of widely accepted evaluation
methodologiesandadvantages,servingdifferentusecasesand
metrics:
data availability scenarios.
• BLEU Score[9]: BLEU is a metric employed to assess
thequalityofmachinetranslations.Itoperatesbymeasur-
A. Supervised Summarization
ing the similarity between n-grams present in machine-
Supervisedsummarizationisamethodthatreliesonlabeled translated sentences and those in human-translated sen-
training data, where human annotators provide summaries tences.ItisgenerallynotedthattheBLEUscoretendsto
for a given set of source texts. Machine learning models decreasewithlongersentencelengths,althoughvariations
are then trained on this data to learn the mapping between inthistrendcanoccurdependingonthetranslationmodel
sourcetextsandtheircorrespondingsummaries.Thisapproach in use.
is particularly effective when high-quality, domain-specific • ROUGE Score[10], [12]: The ROUGE Score assesses
summaries are available for training. theoverlapofn-grams(sequencesofwords)betweenthegeneratedsummaryandreferencesummaries.Itconsiders When comparing the two 7b parameter fine-tuned models,
metrics such as ROUGE-N (unigrams,bigrams,etc.) and MPT-7b-instruct performed slightly better than Falcon-7b-
ROUGE-L (longest common subsequence) to evaluate instruct. However, their overall performance was somewhat
content overlap. similar. These findings underscore the significance of model
• BERT Score[11],[12]:TheBERTScoreutilizescontex- architecture and size in text summarization tasks, as well as
tual embeddings from the BERT model to measure the the potential of OpenAI’s model for achieving state-of-the-art
similarity between the generated summary and reference results in diverse NLP applications.
summaries. It is designed to capture the nuances of lan-
guage and context, providing a robust evaluation metric. VI. CONCLUSION AND FUTURE ENHANCEMENTS
By calculating these metrics for summaries generated with
This research embarked on a comprehensive exploration
different LLMs, we aim to provide a comprehensive assess-
of text summarization techniques using various Large Lan-
ment of their performance, enabling researchers and practi-
guage Models (LLMs), with the goal of shedding light on
tioners to make informed decisions when choosing an LLM
their performance in different settings and scenarios. The
and fine-tuning their summarization models for specific tasks
study encompassed the evaluation of LLMs such as mpt-7b-
and datasets.
instruct, falcon-7b-instruct, and text-davinci-003, as well as
their summarization capabilities across two diverse datasets,
V. INFERENCE WITHDIFFERENT LLMS
’CNN/Daily Mail 3.0.0’ and ’XSum.
In thissection, the resultsof the experimentsare presented,
The experiment results, as indicated by the model per-
wherein a variety of Large Language Models (LLMs) were
formance table and human evaluation of the generated text
utilized to generate summaries for two distinct datasets. The
summaries,highlighttheexceptionalperformanceofOpenAI’s
LLMs employed for these experiments include falcon-7b-
model,text-davinci-003,incomparisontoothermodels.These
instruct, mpt-7b-instruct, and text-davinci-003. The primary
modelsconsistentlydemonstratedasuperiorabilitytoproduce
objective is to offer a comparative analysis of their perfor-
high-quality summaries across various datasets and tempera-
mance concerning text summarization.
ture settings.
A. Experiment Setup In the coming days, this work can be extended to lever-
age inferences from larger samples using higher-parameter
ForeachLLM,experimentswereconductedusingatemper-
models, such as mosaicml/mpt-30b-instructand tiiuae/falcon-
aturevalueof 0.1anda maximumtokenlengthof100.These
40b-instruct, potentially leading to even more robust and
experiments involved summarizing 25 test samples of each
accurate summarizationresults. Additionally,the human eval-
dataset. The process of generating the text summary entailed
uation metrics and inferences can be generated from datasets
the utilization of LangChain and Hugging Face pipelines
with varying word counts and output token lengths. The
for prompt engineering, ensuring precision and efficiency in
continual advancement of Large Language Models (LLMs)
the summarization process. This experiment was executed
with increasing model size and capabilities offers an exciting
by hosting custom Google Compute Engine Virtual Machine
opportunity to explore how these models can further enhance
(GCE VM) instances equipped with NVIDIA T4 Graphics
the quality of text summarization, translation, and content
Processing Units (GPUs) sourced from the Google Cloud
generation. Moreover, the fine-tuning of LLMs on specific
Platform (GCP).
domains and datasets could unlock the potential for domain-
B. Results specific summarizationmodels with exceptionalperformance.
In conclusion, this research contributes valuable insights
TheperformanceofdifferentLLMsontwodistinctdatasets,
into the field of text summarization with LLMs and offers a
utilizing the specified temperature value, was displayed. Met-
glimpseintofutureresearchdirections.As theNLPlandscape
rics were computed for each LLM, offering a comprehensive
continues to evolve, leveraging the capabilities of LLMs, es-
perspective on their summarization capabilities, as available
pecially those offeredby OpenAI, holdsgreatpromise for the
on the GitHub repository cited in this paper[13].
development of advanced Generative AI applications across
Thesetables,asreferencedinTableIandTableII,presenta
diverse business domains.
comprehensive evaluation of various Large Language Models
(LLMs) for text summarization across two distinct datasets:
ACKNOWLEDGMENT
CNN/Daily Mail 3.0.0 and XSum. The performance of each
LLM is assessed using several key metrics, including BLEU, TheauthorwouldliketoexpressheartfeltgratitudetoMihir
ROUGE, and BERT. Sanghvi,MentoroftheKaggleXBIPOCMentorshipProgram
The table highlightsvaryingperformanceacrossLLMsand Cohort 3. Mihir’s invaluable guidance, mentorship, and in-
datasets. Notably, the OpenAI model, text-davinci-003, con- sights have significantly contributed to the success of this
sistently exhibits strong performance, achieving high BLEU, research. Additionally, appreciation is extended to Kaggle for
ROUGE,andBERTScores.Thisexceptionalperformancecan providingtheopportunitytoparticipateintheKaggleXBIPOC
be attributed to davinci being the largest and most powerful Mentorship Program, which facilitated the collaboration and
model, with 175 billion parameters and 45TB of text data. learning experiences that enriched this work.LLM Model Dataset Avg. Word Count ROUGE-1 ROUGE-2 ROUGE-L BERT Score (P/R/F1)
falcon-7b-instruct CNN (n=25) 784.24 0.226 0.053 0.197 0.818 / 0.860 / 0.838
falcon-7b-instruct XSum (n=25) 410.44 0.139 0.014 0.113 0.787 / 0.863 / 0.823
mpt-7b-instruct CNN (n=25) 784.24 0.236 0.060 0.213 0.839 / 0.864 / 0.851
mpt-7b-instruct XSum (n=25) 410.44 0.159 0.024 0.133 0.828 / 0.871 / 0.848
text-davinci-003 CNN (n=25) 784.24 0.272 0.096 0.255 0.854 / 0.883 / 0.868
text-davinci-003 XSum (n=25) 410.44 0.206 0.053 0.173 0.844 / 0.893 / 0.868
TABLE I: Performance Metrics of LLMs on ”CNN/Daily Mail 3.0.0” and ”XSum” Datasets
LLM Model Dataset Avg. Word Count BLEU Score
falcon-7b-instruct CNN (n=25) 784.24 9.4726138403298e-232
falcon-7b-instruct XSum (n=25) 410.44 9.225829346520394e-232
mpt-7b-instruct CNN (n=25) 784.24 9.35328936831654e-232
mpt-7b-instruct XSum (n=25) 410.44 9.542118736121376e-232
text-davinci-003 CNN (n=25) 784.24 0.4896200481408649
text-davinci-003 XSum (n=25) 410.44 0.48979461356547943
TABLE II: Performance Metrics, BLEU Score of LLMs on ”CNN/Daily Mail 3.0.0” and ”XSum” Datasets
Furthermore,thesupportprovidedbyKaggleintheformof [10] ”MetricCardforROUGE,HuggingFaceMetrics.”[Online].Available:
theKaggle-KaggleXGoogleCloudPlatform(GCP)Couponis https://huggingface.co/spaces/evaluate-metric/rouge. [Accessed: 2023-
10-14].
acknowledged. This support enabled access to essential com-
[11] ”Metric Card for BERT Score, Hugging Face Metrics.” [Online].
puting resources on Google Cloud, which was instrumental Available: https://huggingface.co/spaces/evaluate-metric/bertscore. [Ac-
in conducting the experiments for this research. Gratitude is cessed:2023-10-14].
[12] Yan,Ziyou,”Evaluation&HallucinationDetectionforAbstractiveSum-
expressed for the collective efforts of the Kaggle community,
maries” [Online]. Available: https://eugeneyan.com/writing/abstractive/.
which continues to foster a collaborativeand innovativeenvi- [Accessed: 2023-10-14]
ronment for data science and machine learning research. [13] L. Basyal, ”LLMs-Text-Summarization,” GitHub. [Online]. Avail-
able: https://github.com/lbasyal/LLMs-Text-Summarization. [Accessed:
2023-10-14]
REFERENCES
[1] OpenAI GPT-3.5, ”text-davinci-003,”. [Online]. Available:
https://platform.openai.com/docs/models/gpt-3-5. [Accessed: 2023-
10-14]
[2] MosaicML NLP Team, ”Introducing MPT-7B: A New Standard for
Open-Source, Commercially UsableLLMs,”2023.[Online]. Available:
www.mosaicml.com/blog/mpt-7b.[Accessed:2023-10-14]
[3] ”MPT-7B-Instruct, Hugging Face Models.” [Online]. Available:
https://huggingface.co/mosaicml/mpt-7b-instruct. [Accessed: 2023-10-
14]
[4] Chung, Hyung Won, Le Hou, Shayne Longpre, Barret Zoph, Yi
Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Sid-
dhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai,
Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang,
Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew
Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin,
Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei. ”Scaling
Instruction-Finetuned Language Models,” 2022. [Online]. Available:
https://arxiv.org/abs/2210.11416.[Accessed: 2023-10-14]
[5] ”Falcon-7B-Instruct, HuggingFaceModels.”2023.[Online].Available:
https://huggingface.co/tiiuae/falcon-7b-instruct.[Accessed:2023-10-14]
[6] Almazrouei, Ebtesam and Alobeidli, Hamza and Alshamsi, Abdulaziz
and Cappelli, Alessandro and Cojocaru, Ruxandra and Debbah, Mer-
ouaneandGoffinet,EtienneandHeslow,DanielandLaunay,Julienand
Malartic, Quentin and Noune, Badreddine and Pannier, Baptiste and
Penedo, Guilherme. ”Falcon-40B: an open large language model with
state-of-the-art performance.”
[7] ”CNN/DailyMail Dataset,HuggingFaceDatasets.”[Online].Available:
https://huggingface.co/datasets/cnn dailymail.[Accessed:2023-10-14]
[8] ”XSum Dataset, Hugging Face Datasets.” [Online]. Available:
https://huggingface.co/datasets/xsum [Accessed: 2023-10-14]
[9] ”Metric Card for BLEU, Hugging Face Metrics.” [Online]. Available:
https://huggingface.co/spaces/evaluate-metric/bleu.[Accessed:2023-10-
14]