role natural language processing task automatic literary character network construction arthuramalvy vincentlabatut laboratoireinformatiquedavignon laboratoireinformatiquedavignon arthuramalvyunivavignonfr vincentlabatutunivavignonfr richarddufour laboratoiredessciencesdunumriquedenantes richarddufourunivnantesfr abstract threephaseautomaticextractionframework first identify character present text using tech theautomaticextractionofcharacternetworks niques ner alias resolution sec fromliterarytextsisgenerallycarriedoutusing ond detect interaction character one naturallanguageprocessingnlpcascading consider multiple type interaction co pipeline whilethisapproachiswidespread nostudyexistsontheimpactoflowlevelnlp occurrenceconversationsactionshencethis tasksontheirperformance inthisarticlewe processdiffersgiventhetargetedtype thirdgiven conductsuchastudyonaliterarydatasetfo charactersandtheirinteractionsderivetherelation cusingontheroleofnamedentityrecognition ship character extract character nerandcoreferenceresolutionwhenextract network ingcooccurrencenetworks tohighlightthe duetotheirstatisticalnatureandthedifficulty impact task performance start withgoldstandardannotationsprogressively ofthetaskstheyentailnaturallanguageprocessing adduniformlydistributederrorsandobserve nlpcascadingpipelinesappliedtocharacternet theirimpactintermsofcharacternetworkqual workextractionareboundtomakeerrors ity demonstrate ner performance network leveraged many ap depends tested novel strongly af plication general question better fects character detection also show extractthemhasbeencomparativelymuchlessex nerdetected mention alone miss lot ploredandcertainlynotinasystemicway since charactercooccurrencesandthatcoreference extraction generally performed using nlp resolution needed prevent finally wepresentcomparisonpointswithmethods pipeline first step answering question based large language model llm study impact nlp task cludingafullyendtoendoneandshowthat quality final network understanding thesemodelsareoutperformedbytraditional wouldallowthecommunitytoprioritizefuturere nlppipelinesintermsofrecall search effort therefore article pro pose study impact depth artificially introduction adding error step extraction pipeline characternetworksaregraphswhoseverticesrep observe influence specifically focus resent character edge represent rela ner coreference resolution lat tionships seen terremainingachallengingtask weperformour specialcaseofknowledgegraphswherevertices study litbank bamman et al arerestrictedtobeingcharacters suchnetworks standardenglishliterarycorpus tosupportourex havemultipleuses visualizetherelationshipsbe perimentsweimplementextensionstotherecent tweencharactersinanovelsupportliteraryanaly modularcharacternetworkextractionpipelinere sisrochatrochatandtriclotelson nardamalvyetal inordertounderstand et al solve downstream task whether cascading pipeline still competitive recommendation lee jung genre againstllmbasedextractionsystemsandtoguide classificationhettingeretal asindicated future research compare pipeline survey labatut bost many suchsystems tofacilitatereproducibilitywere authorsworkonautomaticallyextractingthesenet leaseallourcodeanddataunderafreelicense workssparavignaandmarazzatodekker etalelsonetalfollowingageneric httpsgithubcomcompnetsplice ced lcsc vvixraour contribution follows first de erroranalysis fine new measure evaluate quality ex mostworksinterestedintheeffectofnlperrors tractednetworks secondweextendtheexisting focusonspecifictasks forthenertaskstanis renard extraction pipeline evaluate laweketalfindthatdifferentnermodels characternetworkdatasetweadaptfromlitbank make different category error rueda ourmeasures anddatasetare afirst steptowards et al highlight recurrent error made systematic benchmarking network ex modelssuchasthedifficultyofdetectingmentions tractionsystemssomethingthatismissinginthe unseeninthetrainingset forthecoreferencetask literature thirdweproposeamodeltosimulate martschatandstrubefocusonrecallerrors error two task ner coreference reso whilechaiandstrubeperformananalysis lution order understand impact onmultilingualcoreferencesystemsandfocuson characternetworkextractionpipeline finallywe twomentionsentitiesthattheyfindhardtorecall compareourpipelinetoendtoendllmmodels tothebestofourknowledgeonlydekkeretal inordertounderstandhowmuchcascadingerrors adoptamoreglobalviewandassesstheef aredetrimentaltoasequentialpipeline fectofnererrorsoncharacternetworks however weorganizetherestofthisarticleasfollows nostudyexistsontheimpactoftheperformance section discus related work highlight main nlp step required extract char ingexistingcharacternetworkextractionpipelines acternetwork ourgoalinthisarticleistofillthis andliteratureonnerandcoreferenceresolution existingvoidintheliteraturebyproposingafirst erroranalysis insectionwedetailourmethods impactstudy includingtheextendedrenardcharacternetwork method extraction pipeline use describe ex periments section discus result terminology section finally review main contri terminology ner coreference butions section present limit aliasresolutionliteraturedivergeandareconfusing workinsection used together section weclarifythetermsthatweuseinthisarticle useformtorefertoatextualrepresentationofa relatedwork character aformcanbeapropernounlianna pronoun definite description characternetworkextractionpipelines princessmeanwhileweusementiontore fertotheoccurrenceofaforminthetext aner character network extraction related knowl system extract subset character men edgegraphextractionbutwithverticesrestricted tions example extract pronoun character share common task refer form mention detected entityrecognitionandlinkingbutthefocusonnar nermodelasanaliasasitstronglyidentifiesa rativesandcharactersimpliesspecializedinstances character meanwhileacoreferencesystemtypi withspecificchallenges callydetectsallmentionsincludingpronounsand booknlpbammanetalisawellknown othergenericconstructs wethereforedistinguish nlppipelinespecializedfornovelsandissome twotypesofmentions aliasmentionsandgeneric time used literature come ex mention tracting character network dekker et al extractionpipeline piper et al author go proposepipelinesspecificallytailoredtocharacter extract character network extend network extraction chaplin sparavi nardextractionpipelineamalvyetal gnaandmarazzatoorcharnettomtrailler designourownpipelinefortheneedsofthisstudy recently amalvy et al propose andcontributedifferentmodules therearemany renard modular character network extraction typesofinteractionsthatwecouldextracttopro pipeline written python article ex duce character network first study tend renard conduct detailed study subjectwechoosetofocusoncooccurrencechar extractionmodule acternetworks theyareconceptuallysimpleandare used type network litera coreference chain never appear turelabatutandbost weconsideranin withouttheotherinotherchains teractionbetweentwocharacterswhentheyappear connected alias last close text range call namebutadifferentfirstnamewedeleteall thecooccurrencewindow ourpipelineisdivided vertex shortest path intofourmainphases nercoreferenceresolution since probably different character optionalstepcharacterunificationandfinallyco family john smith occurrencedetectionandnetworkextraction johnklint weperformflatnerusingthefinetunedbert model devlin et al included renard two alias different inferred trainedontheliterarynerdatasetintroducedby genderwedeletealltheedgesintheshortest dekkeretalandlaterimprovedbyamalvy pathsbetweenthemmr smithandmiss etalb weonlykeepmentionsoftheper smith weinfergenderusingthegendered class titlesandpronounsincoreferencechains coreference resolution use endto applied rule merge end coreference model included renard based thegraphconnectedcomponents usingthealias lee et al joshi et al group extracted algorithm assign model predicts link mention also eachmentiondetectedbythenerorcoreference performsmentiondetection thisisimportantwhen stepstoasinglecharacter extracting cooccurrence character network finally apply cooccurrence detection genericcharactermentionssuchaspronounsare andnetworkextractionstepofrenard thisstepis stillcountedascooccurrences entirelydeterministicandcannotcauseanyerrors characterunificationresemblesaliasresolution errorsbyitself wesimplyconsiderthattwocharac case extraction pipeline define termentionsinthedefinedcooccurrencewindow characterunificationasresolvingeachmentionde form interaction result edge tectedbythenerandcoreferencestepstoasin tween character take account gle character task could described importanceofeachrelationshipweweightedges documentlevelversionofcoreferenceresolution bythenumberofinteractionsbetweencharacters restrictedtocharacters tounifymentionswebase work vala et al perturbationanalysis constructagraphwhereeachvertexisacharacter toassesstheimpactofnerandcoreferencereso aliasasdetectedbynerandweemployasetof lutionerrorsontheextractednetworkswepropose rulestoconnectordisconnectthesevertices start pipeline goldstandard ner rulescanintroduceerrors theyareoftenusedby andcoreferencepredictionsandtoprogressively previous work vala et al ardanuy degrade performance task ob sporlederandthusanalyzingtheirfailure servingtheimpactonthequalityoftheextracted modesisimportant weusethefollowingrules network degrade task performance add uniformly distributed perturbation predic two alias first last name tionscorrespondingtodifferenttypesoferrors incommonweconnectthememmaand emmawoodhouse nerperturbations example consider following gold whentwoaliasesarerelatedbyahypocorism prediction starting point consider two gazetteerjohnandjohnnyweconnect typesofperturbations one two rule hold twoaliaseswhenremovingtitlesweconnect themmr johnandjohnny two alias coreferential con nectthem weconsidertwoaliasestobecoref erentialwhentheyappeartogetherinoneor rep oneeye looked rep goblin add spurious alias mention add false positivestothenerpredictionsbyuniformlysam plinggenericspansuptoacertainspansizefrom thetexttoreduceprecision rep oneeye rep looked rep goblin remove correct alias mention remove true positive ner prediction uni formlysamplingfromthepredictedaliasmentions toreducerecall rep gold network let vertex v v rep p g resent set alias n underlyingcharacter inordertoknowwhetherthe predicted network g correctly contains vertex p andedgessimilartothegoldnetworkg wefirst oneeye looked goblin g need match character since vertex coreferenceresolutionperturbations v isnotnecessarilypresentinv andviceversa p g example consider following gold thuswestartbycomputingamaximumbipartite prediction starting point consider four mappingf v fromthesetofpredictedverticesv pto typesofperturbations v g v thismappingassociatesanypredicted vertexu v toagoldvertexv v ortothenull p g oneeye pranced took poke vertex v meaning u associated goblintryingtobreak concentration characterinv g notethatthenullvertexv repre sentstheemptysetofaliases symmetricallywe add spurious mention add singleton mentionslinkedtonoothermentionstothepre constructamappingg v fromv g tov pv leveragethealiassetsrepresentedbythevertices diction consisting incorrect mention uni tocomputevertexprecisionandvertexrecall formlysamplingnonmentionspansuptoacertain spansize oneeye pranced took poke pre max cid uvp uf uv u goblintryingtobreak concentration v fv v p cid remove correct mention remove cor rec max vvg g vvv v rectlypredictedmentionsfromthepredictionsby v gv v g uniformsampling define vertex f f harmonic v oneeye pranced took poke meanbetweenvertexprecisionandvertexrecall goblintryingtobreak concentration foredgesweusemappingsf andg tocon v v structmappingsf andg whichmapsimilarly addspuriouslinks weaddincorrectcorefer e e edgesetse ande encelinksbetweentwomentionswronglymerging p g coreferencechainstogether weuniformlysample theincorrectlinksinthesetofallpossibleincorrect f vuf vv iff vu v link f euv andf vv v v otherwise oneeye pranced took poke goblintryingtobreak concentration basedonf andg wecomputeedgeprecision e e andedgerecall remove correct link remove correct link predicted mention wrongly split cid cid cidf ee e e pe gcid tingcoreferencechains weuniformlysamplelinks pre max amongallexistingcorrectcoreferencelinks e fe e p cid cid cide pg ee e e gcid oneeye pranced took poke rec e geax e g goblintryingtobreak concentration define edge f f harmonic mean e networkqualitymeasures ofedgeprecisionandedgerecall sincewewanttomeasuretheimpactofnlperrors wealsointroduceweightedvariantsofthesenet extracted network need set mea workmeasureswpre ewrec e andwf ein sures assess quality network order take account weight net compared reference network base workedgesthatcorrespondtothenumberofinter measuresontheworkofvalaetalonalias actionsbetweenconnectedcharacters beforecom resolution putingthemeasureswenormalizetheweightsby letg v e beapredictedcharacternet p p p weemploytheiversonbracketnotationwherep work g g v ge g corresponding ifpropositionp istrueandotherwisedividingbythemaximalnumberofcooccurrences strube wealsoreporttheperformanceof inthenetwork wecomputeprecisionandrecall apipelinewithouttheoptionalcoreferenceresolu asfollows tion step order assess usefulness task weconsideracooccurrencewindowof cid cid cid token wpre max eepcidwf eewecid e fe e p llmbasedapproaches cid cid cid wrec e geax eegcidw ee g wg eecid sincecharacternetworkextractionisusuallyper formedusingcascadingpipelineserrorsmayprop whereweisthefunctionthatcomputesthenor agateanddegradeperformance meanwhilellm malizedweightofedgee weiswhene e based approach less modular explain weightedmeasuresevaluatethequalityofthedis able subject cascading error tributionofweightsinthepredictednetworkand design thereforeinspiredbytherecentadvances arealwayslessthanorequaltotheirunweighted inllmswesurveytheircapabilitytobeusedas counterpart characternetworkextractorsandcomparethemto ourcascadingrenardpipeline weintroducetwo experiment differentllmextractionmethods literarycorpus llmcoref weremarkthatthelastnetworkex perform experiment ner tractionstepcooccurrencedetectioncannotcause andcoreferencelayersofthelitbankliterarycor error simply create edge pu bamman et al since de tweentwocharactersifsomeoftheirmentionsare signedfornestednerwhiletherenardnerstep inthesamecooccurrencewindow thereforein performsflatnerweflattenthelitbankannota thecaseofacooccurrencenetworkwecandefine tions using algorithm implement see ap extraction problem span extraction pendixbfordetails weusecoreferencechainsof extracted span must assigned cor permentionsasthegroundtruthforthecharacter rectcharacter thisproblemdefinitioncouldalso unification step since coreference resolution viewed coreference resolution restricted charactersisequivalenttocharacterunification charactersonly totackletheproblemthiswaywe thenetworkextractionstepcannotcauseerrorson prompt llm mark character mention itsownweextractgoldcharacternetworksusing textwithauniquecharacterid theseannotationsonly llmee given input text simply litbankiscomposedofexcerptsfromnovels promptllmstoproducethecorrespondingchar approximately token since acternetworkinasimplifiedversionofthexml excerpt short restrict analysis basedgraphmlformat thenovelsinvolvingatleastcharacters seeappendixafortheexactprompts weuse prevents high deviation network quality mea fewshotpromptingbyprovidingexamplesofthe sureswhenavertexoranedgeismodifiedinthe task model method make prediction weusetheremainingnovelexcerpts effort parse llm output order fix totraincoreferenceresolutionmodels weuse slightly incorrect output format survey two ofthesenovelsasatrainingsetandthe proprietary model gpt turbo brown et al remainingasadevelopmentset gpto recent open weight pipelineperformance modelllamabinstructtouvronetal weapplyourcharacternetworkextractionpipeline result excerpt select analysis since multiplecoreferenceresolutionmeasuresexistand pipelineperformance noneoftheseareentirelysatisfyingormeasurethe table show ner coreference resolu thing report large set measure tionperformanceofourextendedrenardpipeline cludingmucvilainetalb baggaand baldwinceafluoblancre gptcheckpointgptturbo casens hovy lea moosavi gptocheckpointgptoner performance reported stateof measure wcoref wocoref theart datasets domain f v conlltjongkimsanganddemeulder f e best system obtain f score wf e higher part lack perfor pre v mance may due way transform pre e nested litbank dataset flat ner dataset wpre e observeahighdisparityofperformancebetween rec v novelswithfrangingfromto rec e matchestheobservationsfromdekkeretal wrec e amalvy et al indicating challenge table performanceofourpipelineonnetworkextrac specific novel meanwhile tionwithorwithoutthecoreferenceresolutionstep performanceofcoreferenceresolutionislowerthan whatbammanetalreportsonlitbankfor example report muc bamman coreferenceresolutionperformance etalreports thismaybeduetothe giventhenegativeimpactthatcoreferenceresolu lowernumberofexcerptsinourtrainingsetvs tion seen table question whichisrequiredforouranalysis naturallyarisesiswhetherthistaskisusefulwhen extractingcharacternetworks cooccurrencenet task measure mean min max work extracted alias mention might ner f beasufficientlygoodapproximationofanetwork coref muc extractedwithallmentions inthatcaseperform b ing coreference resolution extract additional ceaf mentionswouldnotbecritical blanc lea measure rec wpre wrec e e e value table performanceofourpipelineonnerandcoref erenceresolution wecomputethemeanminandmax table networkqualitymeasuresforgoldnetworks valuesontheseriesformedbythemeasuresofthe extractedbyignoringcoreferencementions onlyaf novelexcerptsofouranalysisset fectedmeasuresarepresented tableshowstheperformanceofourpipeline understand whether case ex test corpus excerpt depending tract gold network litbank whether add optional coreference step outcoreferenceextractedmentionsandcompute vertexandedgefarehigherwhenomitting networkqualitymeasuresbyconsideringnetworks coreferenceinformationlikelybecausetheperfor withcoreferencementionsasthereference result mance coreference resolution algorithm found table mea nothighenoughleadingtothedetectionofspuri sures affected edge recall weighted edge ous mention misleads character precision weighted edge recall ignoring unificationandcooccurrencedetectionsteps coreference mention prof severely impact discussthequestionoftheutilityofcoreferenceres performance show coreference men olutioninmoredetailinsection ingeneral tions crucial part relationship extracted edgerecallisquitelowmeaningmanycharacter usingcooccurrence interactionsaremissed totryandunderstandtheminimalperformance meanwhile using coreference information neededforcoreferenceresolutiontobeusefulwe provestobeimportanttoincreaseedgerecallmea perform experiment inject gold sures even though coreference resolution lead coreferenceinformationinthepipelineandslowly toacompromisednetworkstructureoverallital degrade performance combine lowsthepipelinetodetectmorecharactermentions thecoreferenceperturbationswedescribedinsec leadingtoabetterestimationoftherelativestrength tion uniformly sampling degradation oftheirinteractions andapplyingit werepeatthisprocessforafixedcorefall addressedbyfutureresearch bf blancf coreferenceresolutionperturbation ceaff pree analysis rece leaf figureshowsthecoreferenceresolutionpertur mucf prev bationsresults recv wpree wrece add spurious mention adding spurious sin gletons affect character unification degradationsteps algorithmandthereforehasnoimpactonthequal figure networkextractionperformancewhenapply ityoftheextractednetwork ingthecoreferenceperturbationsfromsection remove correct mention removing correct mention mainly affect edge measure charac number step observe effect term ters still recognized correctly co ofcoreferenceandnetworkqualitymeasures occurrenceinteractionsarelostduetomissingchar resultsofthisexperimentcanbefoundinfigure actermentionsleadingtofeweredges applying perturbation overall perfor mance measure start decrease addspuriouslinks addingwrongcoreference certainpointafterwhichitstartsreachingaplateau linkssharplydecreasesallnetworkextractionper except edge recall measure effect oc formancemeasures charactersarehardertorecog cursbecauseafterthispointcoreferenceresolution nize interaction missing driven recallonaliasmentionsstartsbeingsolowthatit rule character unification step doesnotaffectthecharacterunificationalgorithm sectionthatarebothfedwronginformation anymoreandotherrulesbasedoncharacteraliases whileitwouldbepossibletonotapplytheserules starttohavemoreinfluence meanwhilethereisa ruleistheonlyonethatallowslinkingtwomen bigdiscrepancybetweenvertexandedgemeasures tionswithcompletelydifferentforms whilevertexmeasurescanstayclosetotheirorig removecorrectlinks networkedgemeasures inalvalueswhencoreferenceresolutionishighly areaffectedthemostbycoreferencelinksremoval degraded case edge measure whilevertexmeasuresstaysomewhatstable coreference resolution crucial whendetectingcooccurrenceasitistheonlyway coreference resolution error prove todetectgenericmentions equal term impact network quality adding spurious link harmful error nerperturbationanalysis whileaddingspurioussingletonsdoesnotaffectour figureshowsthenerperturbationresults characterunificationalgorithm meanwhileother errorsmainlyimpactedgeextractionperformance addspuriousaliasmentions unsurprisingly thereforeifonesconcernistoextractcharacters reducingnerprecisionhasadirecteffectonver onlyaconservativecoreferencealgorithmwithlow texprecisionwhichplummetsasmorenerfalse linkingrecallbuthighlinkingprecisionmightgive positive added edge precision also sharply sufficientperformance howeverwhenextracting decreasesasaresultwhilevertexandedgerecall edgesbetweencharactersbothhighprecisionand slowlydecreasedowntoaplateau recallarenecessaryintermsofmentiondetection removecorrectaliasmentions allrecallmea aswellaslinking suressharplydecreasewhenremovingcorrectalias llmbasedapproaches mention precision measure become unstable finallyundefined asno vertex oredges result llmbased extraction method predictedwhennerrecallreaches llmcoref andllmeecanbefoundintable unsurprisinglynerperformancehasahighim llmcoref observe f score gpto pactonnetworkquality sincenerperformance performs best amongst llm sur varies greatly depending novel seen veyfollowedbyllamabinstructandgpt table enhancing performance challeng turbo llmsparticularlystrugglewithrecallwith ingnovelsisanimportantconcernthatshouldbe gpt turbo llamabinstruct missing aaddspuriousnermention removecorrectnermention pree rece prev recv precision recall wpree wrece degradationsteps degradationsteps figure network quality measure versus number degradation step add spurious alias mention removecorrectaliasmentionperturbations addspuriousmention addspuriouslink bf blancf ceaff pree rece leaf mucf prev degradationsteps degradationsteps recv wpree removecorrectmention removecorrectlink wrece degradationsteps degradationsteps figure networkqualitymeasuresversusthenumberofcoreferenceresolutiondegradationsteps lot character occurrence qualitatively recallstilllagsbehindrenard model either miss lot mention conclusion start hallucinating lot mention con tinuing way output influenced inthisarticlewepresentedastudyontheimpact bytheirpreviouspredictions llamabinstruct ofnlptasksoncharacternetworkextraction alsohastroublerespectingtheoutputformatsome showthatnerperformanceiscrucialtodetecting time generating invalid output gpto much charactersbutthatitdependsheavilyontheconsid moreconsistentalthoughitstillmissesmanymen erednovel thereforefutureresearchshouldfocus tions compared extended improving low ner performance diffi nard pipeline llm result generally lower cultnovels additionallyweshowthatnottackling except edge precision weighted edge thechallengingcoreferenceresolutiontaskimplies measureswheregptotradesprecisionforrecall missingcooccurrencerelationshipsbetweenchar acters task important extract correct llmee resultsaregenerallyhigherthanwith cooccurrenceedgesparticularlywhenitcomesto llmcorefhighlightingtheimportanceoftaskfor edgeweights sinceitremainsdifficultingeneral mulation ifwefocusonfscoresweobservethe ourextractionpipelineexhibitsrelativelylowedge samerankingbetweenllmswithgptobeating extractionperformance wealsoshowthatnotall llamabinstructandgptturbo generally coreference error impact adding llmsdisplayhighvertexandedgeprecisioneven spuriouscoreferencelinksbetweenmentionshas surpassingourpipelinesometimes howevertheir strongest negative impact error wellmcoref llmee renard measure llama gptt gpto llama gptt gpto f v f e wf e pre v pre e wpre e rec v rec e wrec e table comparison network extraction performance llmbased extraction method renardpipeline llamastandsforllamabinstructgptt forgptturbo surveyed developing system able make con modelmayyieldbetterresults howeverthe servativepredictionswhenitcomestocoreference excerpt perform analysis linkingmightbeagoodresearchdirectiontocreate shortapproximatelytokenscompared better character network extraction system un tofullscalenovels theperformanceofllms fortunatelydevelopingcoreferencemodelsatthe inthatsettingmaynotbeashighastheresults scaleofanovelremainsdifficultduetothelackof wereportinourstudy fully annotated one training benchmark ing prompt development datasets withlongdocuments reference even though error propagate cascading pipeline pipeline generally outperformed aamalvyvlabatutandrdufoura learning rank context named entity recognition using llmbased approach however perfor asyntheticdataset inconferenceonempiri manceoftheseapproachesisencouraginggiventhe calmethodsinnaturallanguageprocessingpages fact evaluated fewshot prompt ing setting finetuning llm character net aamalvyvlabatutandrdufourb therole workextractionisthereforeapromisingdirection ofglobalandlocalcontextinnamedentityrecogni research even though pipeline remain tion instannualmeetingoftheassociationfor interpretable computationallinguisticspage limitation aamalvyvlabatutandrdufour renarda modularpipelineforextractingcharacternetworks fromnarrativetexts hal character network extraction pipeline use inspired generic mcardanuyandcsporleder structurebased framework outlined labatut bost clusteringofnovels inrdworkshoponcomputa westillhadtomakeimplementation tionallinguisticsforliteraturepages choice pipeline may behave dif abaggaandbbaldwin algorithmsforscoring ferently regarding task error although coreferencechains instinternationalconference hypothesizethatsimilararchitecturesshould language resource evaluation workshop yieldsimilarresults onlinguisticscoreferencepages bamman lewke mansoor ourperturbationanalysismethodologymay annotated dataset coreference english litera notreflectthedistributionoferrorsfromex ture th language resource evaluation istingmodels howeveritallowsconsidering conferencepages thedifferenttypesofpossibleerrors dbammanspopatandsshen anannotated datasetofliteraryentities inconferenceofthenorth endtoend extraction using llm americanchapteroftheassociationforcomputa survey fewshot prompting setting tionallinguistics humanlanguagetechnologies due resource limitation finetuning volumepagesdbammantunderwoodandnasmith xluo oncoreferenceresolutionperformance bayesian mixed effect model literary character metric inhumanlanguagetechnologyconference inndannualmeetingoftheassociationforcom conference empirical method natural putationallinguisticsvolumepages languageprocessingpages tbrownbmannnrydermsubbiahjdkaplan smartschatandmstrube recallerroranalysis p dhariwal neelakantan p shyam g sastry forcoreferenceresolution inconferenceon aaskellsagarwalaherbertvossgkrueger empiricalmethodsinnaturallanguageprocessing thenighanrchildarameshdzieglerjwu page cwinterchessemchenesiglermlitwin sgraybchessjclarkcbernersmccandlish n moosavi strube corefer aradfordisutskeveranddamodei lan enceevaluationmetricdoyoutrust aproposalfora guagemodelsarefewshotlearners inadvancesin linkbasedentityawaremetric inthannualmeet neuralinformationprocessingsystemsvolume ingoftheassociationforcomputationallinguistics page volume longpaperspages hchaiandmstrube investigatingmultilingual cmtrailler charnetto coreferenceresolutionbyuniversalannotations findingsoftheassociationforcomputationallin piper algeehewitt k sinha ruth guistics emnlppages hvala studyingliterarycharactersandchar acternetwork indigitalhumanities n dekker kuhn van erp evalu ating named entity recognition tool extracting mrecasensandehovy blancimplement social network novel peerjcomputer sci ingtherandindexforcoreferenceevaluation natu encee rallanguageengineering jdevlinmchangkleeandktoutanova yrochat characternetworkanalysisofmile bertpretrainingofdeepbidirectionaltransform zolaslesrougonmacquart indigitalhumanities er language understanding conference thenorthamericanchapteroftheassociationfor computationallinguistics humanlanguagetech rochat triclot le rseaux de per nologiesvolumepages sonnagesdesciencefiction chantillonsdelectures intermdiaires resfuturae elson n dame k mckeown ex tractingsocialnetworksfromliteraryfiction inth rueda e alvarezmellado c lignos annualmeetingoftheassociationforcomputational conllfinegrainederroranalysisandacorrected linguisticspages test set conll english joint ternational conference computational linguis l hettinger becker reger f jannidis tic language resource evaluation lrec ahotho genreclassificationongermannov colingpages el th international workshop database andexpertsystemsapplicationsdexapages acsparavignaandrmarazzato analysisof aplaybymeansofchaplinthecharactersandplaces interactionnetworksoftware internationaljournal mjoshiolevylzettlemoyeranddweld ofsciences bertforcoreferenceresolution baselinesandanal ysis inconferenceonempiricalmethodsinnatural tstanislawekawrblewskaawjcickadziem languageprocessingandthethinternationaljoint bickiandpbiecek namedentityrecognition conferenceonnaturallanguageprocessingpages glass ceiling rd conference computationalnaturallanguagelearning page vlabatutandxbost extractionandanalysis fictional character network survey acm eftjongkimsangandfdemeulder intro computingsurveys ductiontotheconllsharedtask language independentnamedentityrecognition inthconfer k lee l lewis l zettlemoyer enceonnaturallanguagelearningpages endtoend neural coreference resolution con ferenceonempiricalmethodsinnaturallanguage h touvron lavril g izacard x martinet processingpages lachaux lacroix b rozire n goyal e hambro f azhar rodriguez joulin ojleeandjjjung modelingaffectivechar e grave g lample llama open acternetworkforstoryanalytics futuregeneration efficient foundation language model arxiv computersystems csclhvaladjurgensapiperanddruths mr systempromptyouareanexpertinlitera bennethiscoachmanandthearchbishopwalkinto tureandnaturallanguageprocessing abarbutonlyoneofthemgetsrecognized onthe userpromptgivenatextyoumustextract difficultyofdetectingcharactersinliterarytexts acooccurrencecharacternetworkwherevertices conference empirical method natural lan representcharactersandedgesrepresenttheir guageprocessingpages relationship eachedgemusthaveaweightcor respondingtothenumberofinteractionsbetween twocharacters twocharacterswithoutanyin teractionsdonotshareanedge aninteraction betweentwocharactersoccurswhentwooftheir mentionsoccurwithinadistanceoftokens youranswermustbeinasimplifiedgraphmllike format verticesmusthaveanaliasattribute withthelistofaliasesofacharacterseparatedby vilain j burger j aberdeen connolly semicolon lhirschman amodeltheoreticcoreference scoringscheme inthmessageunderstandingcon herearesomeexamplesofthistask ference example input elricwasridinghishorse alongside moonglumtheprinceofruinswaslookingfor hisdarksword output graph node idn aliaseselric prince ruin node node idn aliasesmoonglum largelanguagemodelsprompt node edge ide sourcen targetn weight edge graph use following prompt llmcoref andllmeeextractionmethodsrespectively example input princesslianafeltsadbecausezartharn wasgone lianadecidedsheshouldsleep output graph systempromptyouareanexpertinlitera node idn tureandnaturallanguageprocessing aliasesprincess lianaliana userpromptgivenatextyoumustex node tractcharactersandtheirmentions youran node idn aliaseszarth arn swermustbetheoriginaltextwherecharac node termentionsaretaggedwiththefollowingfor edge ide sourcen targetn mat characteridcharactermen weight tioncharacteridyoumusttagcharac node termentionsonly graph herearesomeexamplesofthistask example b adaptinglitbanktoflatner input elricwasridinghishorse alongside moonglumtheprinceofruinswaslookingfor hisdarksword main body article perform output elricwasridinghishorse experimentsonthelitbankdatasetbammanetal alongsidemoonglumtheprinceof ruinswaslookingforhisdarksword however litbank ner annotation nested renard ner step employ example performs flat ner annotation guideline input princesslianafeltsadbecausezartharn also different litbank original wasgone theprincessdecidedsheshouldsleep ner dataset renard ner step output princesslianafeltsadbecause trained amalvy et al b particular lit zartharnwasgone theprincess bank annotates many generic mention decidedsheshouldsleep anhonourablemanasaliasmentions wethereforeflattenlitbankannotationsusinganalgorithm weimplementwhiletryingtorespecttheoriginal annotationguidelinesasmuchaspossible litbankannotationsconsistsoflayersofnest ing annotated alias mention overlap ourflatteningalgorithmworksasfollows firstwe trytocutannotatedmentionstoaformthatwould accepted alias mention dataset amalvyetalb wedosobyremovinglead ingdeterminerstheandcuttingthecontentof mention first comma afterward filter mention still deemed generic checkingiftheirconstitutingtokensarecapitalized except stopwords alias men tions still overlapping point select theoutermostones togiveanexampletheannotatedmentionthe lordhighchancellorwouldhavebeenshortened aslordhighchancellorandthenacceptedas alias mention since token capi talizedprovideditdoesnotoverlapwithalarger mention contrast generic mention honourablemanwouldhavebeendiscardedsince itstokensarenotcapitalized