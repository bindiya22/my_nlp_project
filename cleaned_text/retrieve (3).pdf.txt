annalsofoperationsresearch httpsdoiorgsw original research identifyingpurchaseintentionthroughdeeplearning analyzingtheqdtextofanecommerceplatform jing maxiaoyu guoxufeng zhao acceptedjunepublished online july theauthorsunderexclusivelicencetospringersciencebusinessmediallcpartofspringernature abstract identifying purchase intention analyzing query document product descriptionqdtextisoneofthemostimportantmeansofpromotingpurchaseratepr inviewofthatcustomerssometimescannotdescribetheirpurchasingintentioninqueries thispaperaimstoidentifypurchaseintentionfromimplicitqueriesbycomputingsemantic similaritybetweenqdandproposesanovelmodelbasedonwordvecalgorithmlong shortterm memory lstm deep structured semantic model dssm besides empiricalanalysisisconductedthroughthekerasframeworkandbasedonthefactualretrieval data home depot ecommerce website selling building material america theresultsshowthattheproposedmodelhasachievedimprovingfscoreontestdataset comparedwithotherexistingmodelsthenovelmodelcombineswordvecandlstmto extracttextfeaturesandappliesdssmtofurtherfetchhighdimensionrepresentationsby maximizing semantic similarity user query description correct merchandiseourproposedmodelcanbeusedtoremoveorminimizesubjectivefactorsin extractingfeaturesimprovestheperformanceofpurchasingintentionidentificationandalso improvesthecustomerexperienceofonlineshopping keywords intentionidentificationlongshorttermmemorylstmdeepstructured semanticmodeldssmdeeplearning b xufengzhao zxpeakoutlookcom jingma majingcom xiaoyuguo xiaoyuguonuaaeducn collegeofeconomicsandmanagementnanjinguniversityofaeronauticsandastronautics nanjingjiangsuchina collegeofmechanicalandelectricalengineeringwenzhouuniversitywenzhouzhejiang china annalsofoperationsresearch introduction identifying purchase intention accurately promote pr world ecommerce accordingtoastudybykweketalwebretailerswillbeabletodevelopeffective efficient webshopping operation attract new potential customer good understandingofthewebshoppersonlinepurchaseintentioncustomersdependonsearch result provided ecommerce platform find desirable product product highersemanticsimilaritytoptheresearchresultsonecommerceplatformliketaobaoand homedepotwhichessentiallyimprovesthechanceofmakingadealcustomersmayswitch toanotherplatformiftheycannotfindtheproducttheywantinthefirstpageofsearching result balakrishnananddwivedinotethatartificialintelligenceaienhancespurchase intention digital assistant however first step enhancing purchase intentionistoidentifythequeryintentionluoetalasecommercehasgainedscale largequantitiesofgoodsaresoldonecommerceplatformsanditisharderforconsumersto searchfortheirdesirableproductsthanbeforeadditionallyoneinevitabletendencywhich isdifferentfromearlieronlineshoppingexperiencesisthatcustomerswillutilizenatural language instead key word searching product want buy luo et alwhichmakesithardertoidentifypurchaseintentionfromtheuserqueryeven worseinsomeverticalecommerceplatformssuchasthebuildingmaterialsonlineshop thenameofaproductisoftenuncommonandcustomershavenoideaofwhatisthenameof theproducttheywanttobuythereforetheytypewhattheywanttodointhequeryboxorask theassistantforhelpiftheecommerceplatformcannotidentifypurchaseintentiontimely would produce bad effect shopping experience thus easily lost customer thereforeecommerceplatformsintendtoenhancetheircustomersshoppingexperience byaddressingtheproblemofidentifyingpurchaseintentionqianetalpeng asthenumberofdataisgrowingdaybydayanumberofstudiesexplorebigdatadriven andmachinelearningmethodstoimprovethelevelandefficiencyinmanagementforexam pleinkumaretaldevelopabigdataanalyticsframeworkwhichoptimizes themaintenancescheduleimprovestheperformanceofremaininglifepredictionandleads toreductioninmaintenancecostinkumaretaldesignabigdatadrivenframe worktoimprovetheaccuracyofdemandforecastsinqayyumetalpropose adepthwisedensenetworktoidentifythecovidinfectedlungsxrayseffectivelyinthe sameyearsenguptaetalexaminethepredictorsofsuccessfulairbnbbookingswith amachinelearningbasedvariableimportanceschemeanddesigncustomizedrecommenda tionsforppaccommodationplatformsinordertoidentifypurchaseintentionaccurately anumberofstudiesalsohavebeendonewithbigdatadrivenandmachinelearningmeth odsuserspurchaseintentionincludesexplicitintentionandimplicitintentionfuliu explicitintentionmeansthattheintentionisincludedinthequerytextwhileimplicit intentionistheintentionthatisnotexpressedexternallybuthavinginonesmindleeet alforexplicitintentionidentificationluoetalproposedaneuralnetwork model bidirectional long shortterm memory bilstm attention mechanism aimingtofindthesemanticsimilaritybetweennaturallanguagecontextwordsandcentral intentiontermandliaoetalbuildanintentionrecognizingmodeltoobtaininten tions ecommerce consumer provide better shopping experience user implicitintentionidentificationtobestudiedinthispaperthepresentproceduresoffinding thepurchaseintentionfromambiguoussearchqueriesaresavetheusersdailyrecords includingbehaviorsofsearchingclickingandpurchasingcheckthepurchasingrecords annalsofoperationsresearch aftersearchingbuildamapbetweenthequeryandthecommodityboughtbythecon sumeriftheproblemofambiguousqueryoccursecommerceplatformwouldconclude purchase intention list commodity according established mapping relation basedontheserulesleeetalconductanexperimentalparadigmwithcollectingand analyzingtheeyetrackingdataandresponsetimebuildingastandardtorecognizeimplicit shopping intention fu liu regard implicit consumption intention recognition multilabel classification task combine multiple feature based follower behaviorintentionbehaviorretweetsbehavioranduserprofilesjiaetalanalyzea largenumberoftextdatawithpurchasingintentionpublishedbyweibousersfuandliu andjiaetalidentifyimplicitintentiononsocialmediaplatformratherthan textofuserquerywhichistheproblemweareintendedtoaddresslietalnoticethat theuserqueryalsocontainsimplicitshoppingintentionandleveragetheencoderdecoder modeltotranslatetheimplicitintentionintothecorrespondingexplicitintentionbyusing theparallelcorporabuiltonthesocialdata fewer research put effort mining user query find implicit intention implicit intention common ecommerce platform especially vertical e commerceplatformthusthemainobjectiveofthispaperistodeviseamodeltoidentify purchaseintentionfromusersquerybasedonsemanticsimilaritycomputationinspiredby informationretrievaltaskthekeytechnologytocalculatesemanticsimilarityisdeeplearn ingwhichhasachievedthegreatperformanceinmostnaturallanguageprocessingnlp task eg devlin et al devised model would utilize deep learning methodstopredicttheproductswhichpossesstheclosestsimilaritywithusersquery identify purchase intention natural language query propose novel intentionidentificationmethodbasedonwordveclstmanddssmwldssminour researchweorganicallyintegratewordveclstmanddssmwhichisbuiltontopof good performance wordveclstm natural language processing eg xiao et al lstmdssm information retrieval palangi et al first use method natural language processing preprocess data preprocessing traintheuniquewordvecmodelusingthecleanedcorpustogiveasemanticrepresentation foreachwordfinallyweuselstmdssmforfurtherextractionoftextfeatures rest paper organized follows sect discus related work sectweprovidethedetailsoftheproposedwldssmmethodinsectwepresentthe experimental process result assessing performance wldssm discus theirimplicationsandweconcludethepaperinthelastsection relatedworks purchaseintentionidentificationmainlyincludesworksoftwodifferentareaswhichinclude semanticrepresentationoftextincludingwordlevelandsentencelevelrepresentationand semanticsimilaritycalculation semanticrepresentationoftext semanticrepresentationofwordsbasedononehotandwordvec onehotencodingisoftenusedtoconvertlabelsintoamatrixtomakesurethedistanceswithin labelsaresamemailealsoonehotencodingtransformationisusedtoconvert annalsofoperationsresearch categoricalfeaturesintocontinuousandbooleandummyvariableswithorforeachoftheir valuesliaoetaltchuentenyawaactuallyonehotencodingisalsoaneasy waytotransformnaturallanguagetomatrixorarraywhichcanbeprocessedbycomputer directlyhoweverthewordvectorsrepresentedbyonehotencodingareindependentand semantic meaning cannot mapped additionally sparse highdimensional vectorswouldcausecurseofdimensionalityeasilywhenthesizeofdictionaryisbigenough segerrodrguezetalonthebasisofonehotencodingmikolovetal proposedwordvecmodelstoembedwordsintovectorsspacesemanticallyfurthermore mikolovetalandrongillustratedthedetailsaboutwordvecincludingthe trainingproceduresontheonehandwordveccouldproducewordvectorssemantically withalowerdimensionandthusimprovesonehotencodingontheotherhandwordvec couldtransformawordintoavectormoreefficientlythantremendouspretraininglanguage modelssuchasbidirectionalencoderrepresentationfromtransformersbertdevlin etalgenerativepretraininggptradfordetalandxlnetyangetal whichallhavemillionsofparameterstooptimizeconsequentlywordvecismore suitableforrealtimefeedbackplatformsbecauseoftheefficiency longshorttermmemoryforsentencerepresentation recently deep learning technology applied field especially field text processing eg kumar et al convolution neural network cnn could learn text semantics convolution extraction text feature acertaincapabilityofantinoisezhouetalintherealworldsequenceisvitalto naturallanguageforexamplelookafterandafterlookinghavedifferentmeaningand cnncannottellanydifferencesfromeachotherthatistosaycnndidnottakesequence factorintoaccountinordertosolvethisproblemmikolovetalproposedrecurrent neural network language model rnnlm give better representation sentence datarecurrentneuralnetworkrnnintroducesconstantcirculationintoitsmodelsothat itcouldprocesssequenceinformationrnnshowsremarkableperformanceinprocessing manytasksconcerningsequenceincludingtasksofnlpegsunetalbutrnn hasalongtermdependenciesproblembengioetalwhenitprocesseslongertexts thelstmarchitectureproposedbyhochreiterandschmidhuberaddressesthis problemoflongtermdependenciesbyintroducingamemorycellthatisabletostorestate informationoverlongperiodoftimeintornn duetoitsgreatperformancelstmhasrecentlybeenusedininformationretrievalfield forextractingsentencelevelsemanticvectorspalangietalandcontextawarequery suggestionsordonietaladditionallyeachempatietalapplydeepneural networkswithlstmtocapturethesentimentfromdisclosureinformationaimingtoassess theassetpricesimpactandkumaretalregardthelstmasabaseclassifiertodetect fraudulentreview semanticsimilaritycalculation generallycosinefunctioniswidelyappliedtocalculatethevalueofsimilarityegkumar etalhoweversemanticsimilaritycalculationdependsonsemanticrepresentation oftexttoagreatextentxiaetalusebilstmtogetthesentencevectorandthen calculatethesimilaritybetweenthetwovectorsofquestionandanswerbycosinefunction todecidewhethertheanswermatchesthequestionornotanetalproposeadeep annalsofoperationsresearch learningmodelbasedonlstmaimingtocalculatethesemanticsimilaritybetweenquestions inquestionansweringsystemwithstateoftheartsotaperformanceunderthesituation without external information resource also nassif et al build neural network modelbasedonlstminordertocalculatethesemanticsimilaritybetweenquestionsthe twomodelsproposedbyanetalandnassifetalonlyadapttothesituationof shorttextbuttherearebothshorttextandlongtextwhenshoppingatecommerceplatforms withqueryintheformofshorttextandproductdescriptionintheformoflongtextdaset alapplysiamesenetworkchopraetaltocalculatesemanticsimilarityand tosearchforsimilarquestionssiamesenetworkconcatenatestwosamenetworkssharing parameterswitheachotherasaresultsiamesenetworkonlyworkswellforsentencepairs whichhavesimilartextlengthhoweverthispaperfocusesoncalculatingsemanticsimilarity betweenthequeryandtheproductdescriptionwhichisdifferentfromcalculatingsimilarity betweenquestionsbecausethetextlengthsofquestionsaresimilarwhilethetextlengths ofqueryandproductdescriptionhaveabiggapitishardtogetagoodperformanceforthe problemtobesolvedinthisstudywithsiamesenetworktheoretically additionally model use semantic similarity improve performance text representation deep structured semantic model dssm mapping query documentsintothesamesemanticspaceundertheconstraintconditionofcosinesimilarity areproposedforfurtherfeatureextractinginthefieldofinformationretrievehuangetal shenetalandpalangietaladdcnnandlstmintodssmnamely cnndssmandlstmdssmrespectivelyandimprovetheperformanceofretrieveresults dssmcnndssmandlstmdssmusethemethodofwordhashingtogettheword vectorrepresentationwhichcannotrepresentawordsemantically inspired existing literature paper mine analyzes qd text data ecommerce platform using wldssm possesses advanced text processing deep learning artificial intelligence technology based great performance dssmininformationretrievaltaskweintroducewordvecandlstmatthesametimein ordertoextractwordlevelandsentencelevelfeaturesemanticallyourresearchattemptsto mineimplicitpurchaseintentionfromsearchqueriestoprovidemoreintelligentservicefor consumersinonlineshopping methodology aimingatidentifyingpurchaseintentionthroughdeeplearningviaanalyzingtheqdtext ecommerce platform home depot paper proposes purchase identification modelbasedonwordveclstmanddssmweshowtheframeworkofthewldssm methodinaschematicdiagraminfig first preprocess corpus via natural language processing tool train wordvec model using processed corpus get word vector q fromwordvecmodelaftersegmentingfinallywesendvectorstolstmsequentiallyand extracthighlevelfeaturevialstmdssmundertheconstraintconditionofcosinefunction definitionoftheproblemandnotations order identify purchase intention calculate similarity score qd thereforeourmodelisdefinedas sqd mssdlwfokrowemarfeht gif annalsofoperationsresearch annalsofoperationsresearch sindicatesthesemanticsimilaritybetweenqd sisarealnumberbetweenand q denotesauserqueryand ddenotesadocumentoftheproductdescription q aretheinputsofthemodelandsistheoutputofthemodelaftercalculatingalltheswe selectamaximumoneandpickupthecorresponding dastheintentionproduct additionallylet beadictionaryand v bethenumberofwordsin qvec dvec indicatethevectorrepresentationof q drespectively istheintentionof q accordingly dvec dvec denote vector representation respectivelyletdbethedimensionofwordvectorw bethewordiandwvi ecbethevector representationofw mql denotesmaximumlengthof qmdl denotesmaximumlengthof dandcdenotesthesizeofwindowoi istheonehotrepresentationofwordi andisthe currentword wordvectorizationbasedonwordvec first need map word semantic vector semantic similarity calculateddssmusesthemethodofwordhashingtotransformwordsintoarraysword hashing could reduce dimensionality would cause word spelling different meaning would ngram representation huang et al inthispaperinspiredbythegreatperformanceofwordvecmailexia etalwetrainwordvecvectorsusingcbowcontinuousbagofwordsmodel theinputlayerofcbowistheonehotencodingsofthewordsbeforeandaftertarget wordasisshowninfigtakesentenceradiantbarrieriseasytouseandinstallasan examplewetransverseeachwordinthesentenceandregarditasthetobepredictedword ifis andcthenthewordsbeforearew radiant andw barrierthe wordsafterarew easyandw tothereforecontextwwww furthermoretaketheonehotencoding owhichhavethesamedimension vastheinputofcbow output cbow huffman tree leaf node created word appearedinthecorpusandtheweightofwhichisdefinedbythefrequencyofwordsasthe conventionalcustomsofcbowifthenodeisclassifiedtotheleftthisnodebelongstothe negative class represents otherwise belongs positive one represents withletbetheundeterminedcoefficientaccordingtotheequationofsigmoidfunction theprobabilityofclassifyinganodetothepositiveclassis cid cid xt ext cid cid thereforetheprobabilityofclasscidifyinganodetocidthenegativeclassis xt letthe j th classificationresultbe p j x j cid cid cid cid cidcid cid cid cidcid p j x j xt j j xt j j foreachwordthereisonlyapathfromroottonodeinhuffmantreewithltimes binaryclassificationtotallytheprobabilityofclassifyingcorrectlyis cidlw cid cid p context p j x j j tupniwobcfoelpmaxe gif annalsofoperationsresearch annalsofoperationsresearch consequentlytheprobabilityofeverywordincorpus classifiedcorrectlyis cid p p context theobjectivefunctionofcbowistomaximize pforthisreasontakethelogarithmof pcontextasthefollowingequation cid l logpcontext w cid cidlw cid cid log p j x j w j cid logcidlw cid cid xt jcidcid j cid cid xt jcidcid j w j cid cidlw cid logcid cid xt jcidcid j cid cid xt jcidcid jcid w j cid cidl cid cid cid cidcid cid cid cid cid cidcidcid j log xt j j log xt j w j cid cid cidcid cid cid cid cid cidcid writel jd j log xt j j log xt j asl j thentheobjectivebecomestomaximizel jwhichhastwoindependentvariables j xtakepartialderivativesforthetwovariablessequentiallyandwecouldget cid cid cid cidcid cid cid cid cid cidcidcid l j j log xt j j log xt j j cid j cid cid cid cid cid cidcid j xt j x j xt j x cid cid cidcid j xt j x cid cid cidcid l j x j xt j j update jandwvec asfollowingequation l j j j j cidl l j w w w context vec vec vec j j stoptheprocedureofiterationwhengradientbecomesverysmallandwefinallygetthe representationforeverywordincorpusthereforewetransformqdintowordvectors andaddthemtoarraysl andl thedimensionsofwhicharesd mql andsd mdl q respectively annalsofoperationsresearch highlevelfeatureextractionbasedonlstmdssm comparingwithmachinelearningdeeplearningextractsfeaturesmoreeffectivelyandcon venientlyandwithouthumaninteractionasaclassicalmodelofinformationretrievedssm couldextractsemanticfeaturesfromtextsofqdeffectivelyhuangetalinthis paper apply dssm identify purchase intention constructing lstmdssm based text qd input vectorized qd lstmdssm train deep learningnetworkandevaluateit putthetth wordrepresentationwvt ec intolstmlayerwhichiswrittenas cid cid h lstm wvt ec aftersendingallvectorsintothelstmlayerwegettherepresentationh foreach q connect h dense layer tanh activation function get semantic representationywhichiswrittenas tanhw hb wherew isthesemanticprojectionmatrixandb isthebiasmatrix throughtheabovestepswecouldgetthesemanticrepresentationof q dwhich aredenotedasy andy nextcalculatethesimilarityscorebetweeny andy whichis q q writtenas cid cid yty rqdcosine qy cid cid qcid cidcid cidd cid cid q aftergettingthetextrepresentationh vialstmandcalculatingthesimilarityscoreif qdaresimilarintherealworldthemodelwoulddragthecorrespondingrepresentation vectorscloserundertheconstraintconditionofcosinesimilarityifqdarelackofresem blance real world model would push corresponding representation vector away constraint condition cosine similarity show text representation undertheconstraintconditionofcosinesimilarityinfig inordertoimplementthedssmmethodwetransformthesemanticsimilaritybetween qand intoposteriorprobabilityfollowinghuangetalwhichiswrittenas cid cid cidcid cid cid exp r qd p q cid dciddexprqdcid isthesmoothingfactorofsoftmaxtheobjectiveofwldssmistomaximize thesemanticsimilarityof qand whichisequallytominimizelcid cid cid cid lcidlog p q qd experiment weconductexperimentstoassesstheperformanceofwldssmindealingwithidentifying purchaseintentionfromuserquerynamelyfindadocumentofproductdescriptionwhich ismostrelatedtouserquerysemanticallyweperformedexperimentsonaserverequipped withnvidiageforcertxgpussixteenamdepyccpusandgb ram running jupyter notebook deep learning model built using kera librarycholletwiththetensorflowbackend annalsofoperationsresearch fig textrepresentationundertheconstraintconditionofcosinesimilarityeachwordwiinthedictionary couldgetwordvector wvi ec inddimensionwordvectorspacefirstgetthewordrepresentationafter applyingwordsegmentationwithqanddnextconcatenatewvi ectoformqvecdv ecanddv ecdenoting cid queryvectorrightandfalsedocumentofproductdescriptionrespectivelyfinallythedistancebetweenqvec cid cid cid anddvecbecomesmallerthanqvecanddvecinthehighlevelsemanticfeaturespaceundertheconstraint conditionofcosinesimilarity dataset obtain qd text ecommerce dataset home depot product search relevancecompetitionshoppersrelyonhomedepotsproductauthoritytofindandbuy latest product get timely solution home improvement need installinganewceilingfantoremodelinganentirekitchenwiththeclickofamouseortap ofthescreencustomersexpectthecorrectresultstotheirqueriesquicklyspeedaccuracy delivering frictionless customer experience essential however since name building material common real world fact shopper notfamiliartoproductnamessothattheplatformcannotprovideasearchresultaccurately therefore develop wldssm discover customer need improve shoppingexperience tablesummarizesthedescriptionofthedatasetforthevalueofrelevancethreepeople ratedtherelevanceofsearchtermandproducttitlewithindicatingperfectlymatchingand denotingtotallynotmatchingandthenaveragedthethreescoretogetthefinalrelevance weshowthetextlengthofproducttitlesearchtermandproductdescriptioninfig httpswwwkagglecomchomedepotproductsearchrelevancedata annalsofoperationsresearch table datasetdescription name description datatype range id auniquekeyofapairofsearchtermproductuid integer productuid auniquekeyofproduct integer producttitle productname text productdescription documentofproductdescription text searchterm userquery text relevance therelevanceofsearchtermandproducttitle realnumber fig textlengthofproducttitleleftsearchtermmiddleandproductdescriptionright preprocessing inthispaperwepreprocessedthedatasetwiththefollowingfivesteps conventionalpreprocessingoftextdataset usefunctionofsnowballstemmer togeneratestemwordsandfunctionoftokenizer tocut word two function nltk package use panda package merge text databeforetrainingwordvecmodelandthemergeddataistheinputofcbowtosimplify theinputofwldssmweconcatenateproducttitleandproductdescriptionasthenew productdescription transformationofsemanticsimilarity theobjectiveofthispaperistoidentifypurchaseintentionthereforewemusttransform thescoreofrelevancetolabelsindicatingwhetherdisthecorrectproductornotfollowing choietalwefirstroundthescoreofrelevancetogetdiscretelabelsnexttake asathresholdandweconceivethatdismatchedwithqlabeledwithifthediscretelabel exceeds procedurestoadapttodssm theinputsofdssmareonlyqandd qandd areinonetoonerelationshipnamely eachqonlyhasoned andviceversaasford dssmrandomlyselectsthenumberofj documentsfromdexceptd thereforewefirstpickupthedatalabeledwithnextwe usethefunctionofdropduplicatestodeletetheduplicateddataincasethat ismatched qfinallywerandomlyselectthenumberof j documentsas foreach qinthis wayourtaskbecomesamulticlassproblemwhichhasthenumberof j class annalsofoperationsresearch table datasplitting number training set verificationset testsetj j j correctqdpair wrongqdpairj j j j unificationoflengthwithpadding fromtableandfigweseethattherangeofthelengthofproducttitleisverylarge areproductdescription andsearchterm thereforeit necessaryto set thresholdt todefinethemaximumlengthforeachfieldforthoselengthsaresmallerthantweadd paddingtofillthegapforthoselengthsexceedtwedeletetheexceededpartifwejust usethemaximumlengthoftextasthetononehandthedimensionoffeatureswouldbe largeresultingintakingtoomuchstoragespaceandtimetotrainthedeeplearningmodel ontheotherhandfeatureswouldbecomesparseanditwouldhaveabadimpactonmodel convergence rate merged producttitle productdescription calculate lengthsoftextofsearchtermandnewproductdescriptionandselectandasthet respectivelycoveringovertexts datasplitting basedontheabovepreprocessingstepswesplitthedataastableshows parametersetting allthehyperparametersinthemodelareadjustedbytheperformanceofthetrainingset thenumberoflstmunitswassettothebatchsizewassettooptimizerwassetto adadeltathelearningrateoftheoptimizerwassettoeepochsweresettowhen thevalidationlossdidnotinferiortothecurrentlowestlosswithinroundthemodelwould stop learning early l regularization bias parameter set rate dropoutwassetto evaluationmeasures inmanypreviousstudiesthestandardfisadoptedastheevaluationstandardsegbasso etalinthispaperfisalsoselectedastheevaluationcriteriaofthemodelsince weareonlyconcernedaboutwhetherthealgorithmsidentifythecorrectproductornotwe ignoretheevaluationofnegativeclass truepositivetpatruepositiveisanoutcomewherethemodelcorrectlypredictsthe positiveclass falsepositivefpafalsepositiveisanoutcomewherethemodelincorrectlypredicts thepositiveclass falsenegativefnafalsenegativeisanoutcomewherethemodelincorrectlypredicts thenegativeclass annalsofoperationsresearch table descriptionofcomparativemodels model reference experiment dssm huangetaluseddssmto theexperimentuseswordhashingto mapaquerytoitsrelevant representqdappliesdssmto documentsatthesemanticlevel extracthighlevelfeatureand finallyusessoftmaxtoclassifyd lstmdssm palangietalused afterembeddingwithwordhashing lstmdssmtogainbetter thelstmisusedtoextract informationretrieveperformance sentencelevelfeatures underthesituationoflongterm semanticallyandfinallysoftmaxis contectinformation appliedtooutputtheprobabilityof classifying wordveccdssm nikhilandsrivastava firstwordvecisusedforword combinedtheconvolutionaldeep embeddingnextcnnanddssm structuredsemanticmodels areappliedfortextfeature cdssmmodelwithwordvec extractionsequentiallyfinally distributedrepresentationsof softmaxfunctionisusedforoutput wordstoclassifyadocumentpair asrelevantirrelavantbyassigninga scoretoit precisionprecisionisusedtonotewhatproportionofpositiveidentificationswasactually correct recallrecallisusedtonotewhatproportionofactualpositiveswasidentifiedcorrectly tp precision tpfp tp recall tpfn precision recall f precision recall comparativemodels toassesstheperformanceofourwldssmmodelagainstothercompetitiveapproacheswe areintendedtoconductablationstudyusingthefollowingexistingmodelsforcomparative purposethedescriptionofcomparativemodelsisshownintable resultanddiscussion table demonstrate proposed model shown bold best correct product identification using qd text widely recognized multiclass classificationtasksareoftenharderthanbinaryclassificationtasksintuitivelywhen j thereisjustonenegativesampleforeachitemofthedatasetandthegoalofthemodelisto differentiatethepositivesamplefromthetwosampleshoweverwhen j themodel hastochoosetherightsamplefrommoresamplesthusas j increaseswhichdenotesthe numberofthenegativesampleincreasesthefscoresdecreaseamongallofthemodels howeverthedecreasingamplitudeofourmodelsperformanceisthesmallestamongallof themodels annalsofoperationsresearch table comparisonofexperimentalresultsofeachmodel model testfj testfj testfj testfj dssm lstmdssm wordveccdssm wldssm table confusionmatrix actualclass predictedclass j true false true false table confusionmatrix actualclass predictedclass j true false false true false false table confusionmatrix actualclass predictedclass j true false false false true false false false tablealsoshowstheresultsoftheablationstudywherewecomparearangeofmodels use dssm combination using dssm lstm well combination using dssm cnn wordvec looking dssm lstmdssm model see thatthereisaminorperformancedifferencebetweenthemwhenwelookatwordvecc dssmmodelhoweveritobtainsasubstantialimprovementoverdssmandlstmdssm futhermore wldssm achieves minor improvement wordveccdssm hence provingwldssmasamorecompetitiveapproach wecanseetheresultinconfusionmatrixwhichisanerrortablethatisusedformeasuring andvisualizingoftheperformanceofanyclassificationalgorithmsinerrorconfusionmatrix column represents predicted class measure row represents actual class measureskumaretalwecalculatetheconfusionmatrixforeach j viaapifrom scikitlearn library result shown table see thefirstrowhasthevalueswhichisdifferentfromanormalconfusionmatrixthereason negative sample dataset construct manually httpsscikitlearnorgstablemodulesgeneratedsklearnmetricsconfusionmatrixhtml annalsofoperationsresearch table confusionmatrix actualclass predictedclass j true false false false false true false false false false fig impactofoptimizertuningonfadadeltavsnadam input item positive data model would construct j item negative dataautomaticallythese j itemsaretogetherandthenegativesamplescannotappear independentlythusthereisnovaluefortherowsoffalseinactualclassthesetablesshow thatthevalueoftpdecreasesas j increase figillustratesthevariationoffscorewithoptimizergenerallynadamoptimizeris moreeffectiveinachievinghigherfscorethanadadeltafordssmandlstmdssm opposite wvdssm wldssm specifically performance two optimizers j wldssm j lstmdssmadditionallynadamoptimizerhashigherconvergencyspeedthanadadelta dssmcandraw q closerwhilepull q awayforinformationretrieval thispaperusesdssmtoconductpurchaseintentionidentificationasacomparativemodel since method word embedding word hashing model dssm cannot extract semanticfeatureofwordsandignorethesequencesofwordslstmdssmmodeladds lstmneuralnetworktodssmwhichcaneffectivelylearnsequenceinformationandextract sentencelevelfeaturesothefinalmodelsidentificationperformanceisbetterthandssm wordveccdssm replaces word hashing model wordvec algorithm aiming getword embeddingsemantically ratherthanindependentwordembeddingadditionally wordveccdssmaddsconvolutionallayertodssmwhichcarriesouttheconvolution annalsofoperationsresearch extractionoftextfeaturestolearntextsemanticstheidentificationperformanceissignifi cantlyenhancedwhendssmintroduceswordvecandconvolutionallayer howeverconvolutionallayeralsohasnoabilitytorecordthesequenceinformationamong wordvectorsinordertoextractthesentencelevelfeatureandstoresequenceinformation thispaperadoptslstmneuralnetworkthatconnectsnodesbetweenhiddenlayersandadds three control unit input gate output gate forget gate could remember past information solve problem long sequence dependence therefore performanceofclassificationisobviouslyimprovedandsemanticlearningisenhancedvia wordvecandlstm conclusion shoppersrelyonecommerceplatformstofindandbuythelatestproductsspeedaccuracy anddeliveringafrictionlesscustomerexperienceareessentialforecommerceplatforms howevercustomersoftenleaveaquerywithambiguousintentionresultinginunsatisfied searchingresultsanddeterioratingcustomerexperienceespeciallyinverticalecommerce querieswithambiguousintentionareverycommoninthatsomeproductnamesareunpopular user even idea name product need although several deeplearningmodelstoidentifypurchaseintentionhavebeendevelopednoneofthesegive aglancetodssmwhichpossessgreatperformanceininformationretrievalourresearch proposesamodelcombiningwordvecandlstmaswellasdssmthatcanaccurately predict correct product improve customer shopping experience ecommerce platform summarize theoretical practical contribution well future researchopportunitiesasfollows theoreticalcontribution paper proposes purchase intention identification model based existing text semanticsanalysisthisresearchusesadvancedtextprocessingdeeplearningandartificial intelligencetechnologytomineandanalyzetheqdtextdataontheecommerceplatforms basedonpeerresearchaimingataddressingtheproblemofidentifyingpurchaseintention fromusersqueryweconstructwldssmmodelforpurchaseintentionidentificationby analyzingtheqdtextdatabasedonwordveclstmanddssmthismodelisusedto identifythepurchaseintentionontheecommerceplatformtheproposedmodelisbetter existing model term f score combined advantage technologyincludingwordveclstmanddssmwldssmimprovestheperformance ofpurchaseintentionidentificationadditionallydataimbalanceisverycommonandhasa badimpactontrainingdeeplearningmodelsthestrategyofgeneratingnegativesamples make data class balanced strategy may helpful training deep learningmodels practicalcontribution depend research method proposed paper customer could find buy productsquicklyandaccuratelyourmodelcanclassifyadocumentofproductdescription relevantirrelevant relevant product mean possesses biggest semantic similarityscorewithuserqueryanditmaybethedesirableproductinthehighestdegreethe annalsofoperationsresearch irrelevantproductmeansthatthesemanticsimilarityscoreislowerthanthebiggestsemantic similarityscoreanditmaybenotthecorrectproductshopperisfindingfortheecommerce platformstheycouldutilizethismethodtooutputsemanticsimilarityscoresofqdand theplatformscansortthescoresinreverseorderaccordingtothesortresultstheplatform couldreturnalistofproductsfortheuserqueryadditionallyourmodelcouldremoveor minimizehumaninputinsearchrelevanceevaluationwhichisaslowandsubjectiveprocess accordingtoourmodeltheplatformscouldimproveshoppingexperienceandthusattract retain customer strengthen competitive advantage customer method allowthemtotypenaturallanguageorwhattheywanttodoeglaythefoundationsinthe queryboxincasethatcustomersdonotknowthenameoftheproducttheywant futurescopeofresearch despitethesesignificantinsightstherearestillsomelimitationsinthispaperfirstthepro posedmodelhasonlybeentestedonadatasetfromthehomedepotplatformshowever differentresultsmighthavebeenobtainedifthemodelhadbeentestedonotherecommerce platformsthefindingsmightnotbedirectlyapplicableonotherdatasetsbecausethelan guages may different overcome limitation research certainly explore corresponding preprocessing method different language model shouldbetestedonmultipledatasetscollectedfromadditionalonlineplatformssecondwe developourmodelusingwordvecwhichistrainedbythecurrentcorpusifanewword emerged could get semantic representation wordvec model future wewouldexploreadynamicwordrepresentationmethodandcombineitwiththeexisting moduleofourmodel acknowledgement thisstudywassupportedbythenationalnaturalsciencefoundationofchinaunder grantnumberandandthefundamentalresearchfundsforthecentraluniversities undergrantnumbernw reference anchuangjchangshuangzquestionsimilaritymodelingwithbidirectionallongshort termmemoryneuralnetworkinieeefirstinternationalconferenceondatascienceincyberspace dscppieee balakrishnanjdwivediykconversationalcommerceenteringthenextstageofaipowered digitalassistantsannalsofoperationsresearchpp bassosceselliatettamanziarandomsamplingandmachinelearningtounderstandgood decompositionsannalsofoperationsresearch bengioyfrasconipsimardptheproblemoflearninglongtermdependenciesinrecurrent networksinieeeinternationalconferenceonneuralnetworksppieee choijikallumadismitrabagichteinejavedfsemanticproductsearchformatching structuredproductcatalogsinecommercearxivpreprintarxiv cholletfkerashttpsgithubcomfcholletkeras choprashadsellrlecunylearningasimilaritymetricdiscriminativelywithapplicationto faceverificationinieeecomputersocietyconferenceoncomputervisionandpatternrecognition cvprvolppieee dasayenalahchinnakotlamshrivastavamtogetherwestandsiamesenetworksfor similarquestionretrievalinproceedingsofthethannualmeetingoftheassociationforcomputational linguisticsvolumelongpaperspp devlinjchangmwleektoutanovakbertpretrainingofdeepbidirectionaltransformers forlanguageunderstandingarxivpreprintarxiv annalsofoperationsresearch eachempatipsrivastavaprkumaratankhguptasvalidatingtheimpactofaccounting disclosuresonstockmarketadeepneuralnetworkapproachtechnologicalforecastingandsocial change fubliutimplicituserconsumptionintentrecognitioninsocialmediajournalofsoftware hochreitersschmidhuberjlongshorttermmemoryneuralcomputation huangpshexgaojdenglaceroaheckllearningdeepstructuredsemantic modelsforwebsearchusingclickthroughdatainproceedingsofthendacminternationalconference oninformationknowledgemanagementpp jiayhandlinhwanggxialconsumptionintentrecognitionalgorithmsforweibo usersactascientiarumnaturaliumuniversitatispekinensispp kumarasinghjpdwivediykrananpadeepmultimodalneuralnetworkforinformative twittercontentclassificationduringemergenciesannalsofoperationsresearchpp kumaragopalrdshankarrtankhfraudulentreviewdetectionmodelfocusingon emotionalexpressionsandexplicitaspectsinvestigatingthepotentialoffeatureengineeringdecision supportsystems kumarashankarraljohaninrabigdatadrivenframeworkfordemanddrivenforecasting witheffectsofmarketingmixvariablesindustrialmarketingmanagement kumarashankarrthakurlsabigdatadrivensustainablemanufacturingframeworkfor conditionbasedmaintenancepredictionjournalofcomputationalscience kwekcltanhplautcinvestigatingtheshoppingorientationsononlinepurchase intention ecommerce environment malaysian study journal internet banking commerce leedgleekhleesyimplicitshoppingintentionrecognitionwitheyetrackingdata andresponsetimeinproceedingsoftherdinternationalconferenceonhumanagentinteractionpp licduywangsminingimplicitintentionusingattentionbasedrnnencoderdecodermodel ininternationalconferenceonintelligentcomputingppspringer liaoypengyshisshivyuxearlyboxofficepredictioninchinasfilmmarketbased onasliaotackingfusionmodelannalsofoperationsresearchpp luoxgongychenxcentralintentionidentificationfornaturallanguagesearchqueryin ecommerceinecomsigir maillebjointsentenceandaspectlevelsentimentanalysisofproductcommentsannalsof operationsresearchpp mikolovtchenkcorradogdeanjefficientestimationofwordrepresentationsinvector spacearxivpreprintarxiv mikolovtkarafitmburgetlcernockyjkhudanpursrecurrentneuralnetworkbased languagemodelininterspeechvolppmakuhari mikolovtsutskeverichenkcorradogsdeanjdistributedrepresentationsofwords andphrasesandtheircompositionalityinadvancesinneuralinformationprocessingsystemspp nassifhmohtaramimglassjlearningsemanticrelatednessincommunityquestionanswering usingneuralmodelsinproceedingsofthestworkshoponrepresentationlearningfornlppp nikhilnsrivastavammcontentbaseddocumentrecommenderusingdeeplearningin internationalconferenceoninventivecomputingandinformaticsicicippieee palangihdenglshenygaojhexchenjsongxwardrsemanticmodelling withlongshorttermmemoryforinformationretrievalarxivpreprintarxiv palangihdenglshenygaojhexchenjetaldeepsentenceembeddingusinglong shorttermmemorynetworksanalysisandapplicationtoinformationretrievalieeeacmtransactions onaudiospeechandlanguageprocessing pengxresearchonrecognitionmethodincustomerpurchaseintentionbasedonintelligentcustomer servicelearningmastersthesisshandonguniversityoffinanceandeconomics qayyumarazzakitanveermkumaradepthwisedenseneuralnetworkforautomatic covidinfectiondetectionanddiagnosisannalsofoperationsresearchpp qianydingxliutyihengcidentificationmethodofuserstravelconsumptionintention inchattingrobotscisininform radfordanarasimhanksalimanstsutskeveriimprovinglanguageunderstandingby generativepretraining annalsofoperationsresearch rodrguezpbautistamagonzalezjescalerasbeyondonehotencodinglowerdimen sionaltargetembeddingimageandvisioncomputing rongxwordvecparameterlearningexplainedarxivpreprintarxiv segercaninvestigationofcategoricalvariableencodingtechniquesinmachinelearningbinary versusonehotandfeaturehashing senguptapbiswasbkumarashankarrguptasexaminingthepredictorsofsuccessful airbnbbookingswithhurdlemodelsevidencefromeuropeaustraliausaandasiapacificcitiesjournal ofbusinessresearch shenyhexgaojdenglmesnilgalatentsemanticmodelwithconvolutionalpooling structureforinformationretrievalinproceedingsoftherdacminternationalconferenceonconference oninformationandknowledgemanagementpp sordoni bengio vahabi h lioma c grue simonsen j nie jy hierarchical recurrentencoderdecoderforgenerativecontextawarequerysuggestioninproceedingsoftheth acminternationalonconferenceoninformationandknowledgemanagementpp sunxxuwjianghwangqadeepmultitasklearningapproachforairqualityprediction annalsofoperationsresearch tchuentednyawasrealestatepriceestimationinfrenchcitiesusinggeocodingandmachine learningannalsofoperationsresearchpp xiahliujzhangzjidentifyingfintechriskthroughmachinelearninganalyzingtheqa textofanonlineloaninvestmentplatformannalsofoperationsresearchpp xiaolwanggzuoyresearchonpatenttextclassificationbasedonwordvecandlstm inthinternationalsymposiumoncomputationalintelligenceanddesigniscidvolpp ieee yangzdaizyangycarbonelljsalakhutdinovrrleqvxlnetgeneralizedautore gressivepretrainingforlanguageunderstandingadvancesinneuralinformationprocessingsystems zhoufjinldongjreviewofconvolutionalneuralnetworkchinesejournalofcomputers publishersnote springernatureremainsneutralwithregardtojurisdictionalclaimsinpublishedmapsand institutionalaffiliations annals operationsresearchisacopyrightof springerallrightsreserved